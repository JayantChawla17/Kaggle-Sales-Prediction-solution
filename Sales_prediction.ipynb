{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import ensemble\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ToWeight(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "\n",
    "def rmspe(yhat, y):\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n",
    "    return rmspe\n",
    "\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    # y = y.values\n",
    "    y = y.get_label()\n",
    "    y = np.exp(y) - 1\n",
    "    yhat = np.exp(yhat) - 1\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n",
    "    return \"rmspe\", rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_store = pd.read_csv('store.csv')\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and feature building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation on train data \n",
    "df_train.fillna(0, inplace=True)\n",
    "df_train['Date'] = pd.to_datetime(df_train['Date'])\n",
    "df_train['Month'] = df_train.Date.apply(lambda dt: dt.month)\n",
    "df_train['Year'] = df_train.Date.apply(lambda dt: dt.year)\n",
    "df_train['Day'] = df_train.Date.apply(lambda dt: dt.day)\n",
    "df_train['wom'] = df_train.Date.apply(lambda dt: (dt.day-1)//7 + 1)\n",
    "df_train_custsales = df_train[['Store','Customers','Sales']]\n",
    "df_train['Open'] = df_train['Open'].map(lambda x : float(x))\n",
    "df_train['SchoolHoliday'] = df_train['SchoolHoliday'].astype(int) \n",
    "df_train = df_train.merge(df_store,  on = 'Store')\n",
    "\n",
    "df_test.fillna(0, inplace=True)\n",
    "df_test['Date'] = pd.to_datetime(df_test['Date'])\n",
    "df_test['Month'] = df_test.Date.apply(lambda dt: dt.month)\n",
    "df_test['Year'] = df_test.Date.apply(lambda dt: dt.year)\n",
    "df_test['Day'] = df_test.Date.apply(lambda dt: dt.day)\n",
    "df_test['wom'] = df_test.Date.apply(lambda dt: (dt.day-1)//7 + 1)\n",
    "df_test['SchoolHoliday'] = df_test['SchoolHoliday'].astype(int) \n",
    "df_test = df_test.merge(df_store,  on = 'Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['prev_wom'] = df_train.groupby(['Month','DayOfWeek','wom','Store'])['Sales'].shift(1)\n",
    "df_train['prev_wom'].fillna(df_train['Sales'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "for_test = df_train[(df_train[\"Date\"]>=datetime(2014,7,1)) & (df_train[\"Date\"]<=datetime(2014,9,30))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_test = for_test[['Month','DayOfWeek','wom','Store','Sales']]\n",
    "for_test.columns = ['Month','DayOfWeek','wom','Store','prev_wom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(df_test,for_test,how='left',on=['Month','DayOfWeek','wom','Store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_test_na = df_train.groupby('Store')['prev_wom'].median().reset_index()\n",
    "for_test_na.columns = ['Store','prev_wom_change']\n",
    "df_test = pd.merge(df_test,for_test_na,how='left',on=['Store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['prev_wom'].isnull(),'prev_wom']=df_test['prev_wom_change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>...</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "      <th>prev_wom</th>\n",
       "      <th>prev_wom_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3740.0</td>\n",
       "      <td>4209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>857</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-09-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4383.0</td>\n",
       "      <td>4209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1713</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-09-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4381.0</td>\n",
       "      <td>4209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2569</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-09-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3676.0</td>\n",
       "      <td>4209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3425</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4209.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  Store  DayOfWeek       Date  Open  Promo StateHoliday  SchoolHoliday  \\\n",
       "0     1      1          4 2015-09-17   1.0      1            0              0   \n",
       "1   857      1          3 2015-09-16   1.0      1            0              0   \n",
       "2  1713      1          2 2015-09-15   1.0      1            0              0   \n",
       "3  2569      1          1 2015-09-14   1.0      1            0              0   \n",
       "4  3425      1          7 2015-09-13   0.0      0            0              0   \n",
       "\n",
       "   Month  Year       ...         Assortment  CompetitionDistance  \\\n",
       "0      9  2015       ...                  a               1270.0   \n",
       "1      9  2015       ...                  a               1270.0   \n",
       "2      9  2015       ...                  a               1270.0   \n",
       "3      9  2015       ...                  a               1270.0   \n",
       "4      9  2015       ...                  a               1270.0   \n",
       "\n",
       "  CompetitionOpenSinceMonth CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  \\\n",
       "0                       9.0                   2008.0       0              NaN   \n",
       "1                       9.0                   2008.0       0              NaN   \n",
       "2                       9.0                   2008.0       0              NaN   \n",
       "3                       9.0                   2008.0       0              NaN   \n",
       "4                       9.0                   2008.0       0              NaN   \n",
       "\n",
       "   Promo2SinceYear  PromoInterval  prev_wom  prev_wom_change  \n",
       "0              NaN            NaN    3740.0           4209.0  \n",
       "1              NaN            NaN    4383.0           4209.0  \n",
       "2              NaN            NaN    4381.0           4209.0  \n",
       "3              NaN            NaN    3676.0           4209.0  \n",
       "4              NaN            NaN       0.0           4209.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['StoreType'] == 'a', 'StoreType'] = '1'\n",
    "df_train.loc[df_train['StoreType'] == 'b', 'StoreType'] = '2'\n",
    "df_train.loc[df_train['StoreType'] == 'c', 'StoreType'] = '3'\n",
    "df_train.loc[df_train['StoreType'] == 'd', 'StoreType'] = '4'\n",
    "\n",
    "df_test.loc[df_test['StoreType'] == 'a', 'StoreType'] = '1'\n",
    "df_test.loc[df_test['StoreType'] == 'b', 'StoreType'] = '2'\n",
    "df_test.loc[df_test['StoreType'] == 'c', 'StoreType'] = '3'\n",
    "df_test.loc[df_test['StoreType'] == 'd', 'StoreType'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['Assortment'] == 'a', 'Assortment'] = '1'\n",
    "df_train.loc[df_train['Assortment'] == 'b', 'Assortment'] = '2'\n",
    "df_train.loc[df_train['Assortment'] == 'c', 'Assortment'] = '3'\n",
    "\n",
    "df_test.loc[df_test['Assortment'] == 'a', 'Assortment'] = '1'\n",
    "df_test.loc[df_test['Assortment'] == 'b', 'Assortment'] = '2'\n",
    "df_test.loc[df_test['Assortment'] == 'c', 'Assortment'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['StateHoliday'] = df_train['StateHoliday'].replace(0, '0')\n",
    "df_train.loc[df_train['StateHoliday'] == 'a', 'StateHoliday'] = '1'\n",
    "df_train.loc[df_train['StateHoliday'] == 'b', 'StateHoliday'] = '2'\n",
    "df_train.loc[df_train['StateHoliday'] == 'c', 'StateHoliday'] = '3'\n",
    "\n",
    "df_test['StateHoliday'] = df_test['StateHoliday'].replace(0, '0')\n",
    "df_test.loc[df_test['StateHoliday'] == 'a', 'StateHoliday'] = '1'\n",
    "df_test.loc[df_test['StateHoliday'] == 'b', 'StateHoliday'] = '2'\n",
    "df_test.loc[df_test['StateHoliday'] == 'c', 'StateHoliday'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['PromoInterval'].isnull(), 'PromoInterval'] = '1'\n",
    "df_train.loc[df_train['PromoInterval'] == 'Jan,Apr,Jul,Oct', 'PromoInterval'] = '2'\n",
    "df_train.loc[df_train['PromoInterval'] == 'Feb,May,Aug,Nov', 'PromoInterval'] = '3'\n",
    "df_train.loc[df_train['PromoInterval'] == 'Mar,Jun,Sept,Dec', 'PromoInterval'] = '4'\n",
    "\n",
    "\n",
    "df_test.loc[df_test['PromoInterval'].isnull(), 'PromoInterval'] = '1'\n",
    "df_test.loc[df_test['PromoInterval'] == 'Jan,Apr,Jul,Oct', 'PromoInterval'] = '2'\n",
    "df_test.loc[df_test['PromoInterval'] == 'Feb,May,Aug,Nov', 'PromoInterval'] = '3'\n",
    "df_test.loc[df_test['PromoInterval'] == 'Mar,Jun,Sept,Dec', 'PromoInterval'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_data = df_train_custsales.groupby('Store').agg({'Sales':'mean','Customers':'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.merge(mean_data,  on = 'Store')\n",
    "\n",
    "df_test = df_test.merge(mean_data,  on = 'Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['CompetitionDistance'].fillna(df_train['CompetitionDistance'].median(), inplace=True)\n",
    "df_train['CompetitionDistance'] = np.log(df_train.CompetitionDistance) + 1\n",
    "\n",
    "df_test['CompetitionDistance'].fillna(df_test['CompetitionDistance'].median(), inplace=True)\n",
    "df_test['CompetitionDistance'] = np.log(df_test.CompetitionDistance) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only the open days \n",
    "df_train = df_train[df_train[\"Open\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = df_train[df_train.columns.drop(['Day','Store','Date','CompetitionOpenSinceMonth','CompetitionOpenSinceYear','Promo2SinceWeek','Promo2SinceYear','PromoInterval','Year'])]\n",
    "\n",
    "df_test = df_test[df_test.columns.drop(['Day','Store','Date','CompetitionOpenSinceMonth','CompetitionOpenSinceYear','Promo2SinceWeek','Promo2SinceYear','PromoInterval','Year'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert factors\n",
    "df_train = pd.get_dummies(df_train, columns=['DayOfWeek', 'StateHoliday','StoreType', 'Assortment','Month'], dummy_na=False)\n",
    "\n",
    "df_test = pd.get_dummies(df_test, columns=['DayOfWeek', 'StateHoliday','StoreType', 'Assortment','Month'], dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['StateHoliday_2']=0\n",
    "df_test['StateHoliday_3']=0\n",
    "\n",
    "df_test['Month_1'] = 0\n",
    "df_test['Month_2'] = 0\n",
    "df_test['Month_3'] = 0\n",
    "df_test['Month_4'] = 0\n",
    "df_test['Month_5'] = 0\n",
    "df_test['Month_6'] = 0\n",
    "df_test['Month_7'] = 0\n",
    "df_test['Month_10'] = 0\n",
    "df_test['Month_11'] = 0\n",
    "df_test['Month_12'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['Sales_x']\n",
    "\n",
    "id_order = df_test['Id']\n",
    "\n",
    "df_train = df_train.drop([\"Sales_x\",  \"Customers_x\"],axis=1)\n",
    "\n",
    "df_test = df_test.drop([\"Id\"],axis=1)\n",
    "\n",
    "df_train = df_train.rename(index=str, columns={\"Sales_y\": \"Sales\", \"Customers_y\": \"Customers\"})\n",
    "\n",
    "df_test = df_test[df_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split in Test and Train and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and Train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train, y, test_size=0.05, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use log on target column y\n",
    "dtrain = xgb.DMatrix(X_train, np.log(y_train + 1))\n",
    "dvalid = xgb.DMatrix(X_test, np.log(y_test + 1))\n",
    "dtest = xgb.DMatrix(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking parameters\n",
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"eta\": 0.3,\n",
    "          \"max_depth\": 7,\n",
    "          \"subsample\": 0.75,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"silent\": 1\n",
    "          }\n",
    "\n",
    "num_trees = 400\n",
    "\n",
    "watchlist = [(dvalid, 'eval'), (dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:5.78979\ttrain-rmse:5.78949\teval-rmspe:0.996898\ttrain-rmspe:0.996888\n",
      "Multiple eval metrics have been passed: 'train-rmspe' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmspe hasn't improved in 50 rounds.\n",
      "[1]\teval-rmse:4.05549\ttrain-rmse:4.05491\teval-rmspe:0.982099\ttrain-rmspe:0.982078\n",
      "[2]\teval-rmse:2.84173\ttrain-rmse:2.84106\teval-rmspe:0.940126\ttrain-rmspe:0.940068\n",
      "[3]\teval-rmse:1.99361\ttrain-rmse:1.99293\teval-rmspe:0.860671\ttrain-rmspe:0.860528\n",
      "[4]\teval-rmse:1.40021\ttrain-rmse:1.39968\teval-rmspe:0.749086\ttrain-rmspe:0.748777\n",
      "[5]\teval-rmse:0.987206\ttrain-rmse:0.986777\teval-rmspe:0.622122\ttrain-rmspe:0.621297\n",
      "[6]\teval-rmse:0.699649\ttrain-rmse:0.699377\teval-rmspe:0.498799\ttrain-rmspe:0.49706\n",
      "[7]\teval-rmse:0.502295\ttrain-rmse:0.502224\teval-rmspe:0.392577\ttrain-rmspe:0.389488\n",
      "[8]\teval-rmse:0.367645\ttrain-rmse:0.367814\teval-rmspe:0.310347\ttrain-rmspe:0.304934\n",
      "[9]\teval-rmse:0.279322\ttrain-rmse:0.279876\teval-rmspe:0.253435\ttrain-rmspe:0.245251\n",
      "[10]\teval-rmse:0.22204\ttrain-rmse:0.222982\teval-rmspe:0.21758\ttrain-rmspe:0.20598\n",
      "[11]\teval-rmse:0.187238\ttrain-rmse:0.188434\teval-rmspe:0.198167\ttrain-rmspe:0.184233\n",
      "[12]\teval-rmse:0.167047\ttrain-rmse:0.16831\teval-rmspe:0.188409\ttrain-rmspe:0.173254\n",
      "[13]\teval-rmse:0.156412\ttrain-rmse:0.157689\teval-rmspe:0.185162\ttrain-rmspe:0.168561\n",
      "[14]\teval-rmse:0.150361\ttrain-rmse:0.151707\teval-rmspe:0.184202\ttrain-rmspe:0.166769\n",
      "[15]\teval-rmse:0.147323\ttrain-rmse:0.148545\teval-rmspe:0.184466\ttrain-rmspe:0.166342\n",
      "[16]\teval-rmse:0.145229\ttrain-rmse:0.145893\teval-rmspe:0.184012\ttrain-rmspe:0.165894\n",
      "[17]\teval-rmse:0.144002\ttrain-rmse:0.144677\teval-rmspe:0.184211\ttrain-rmspe:0.166102\n",
      "[18]\teval-rmse:0.143464\ttrain-rmse:0.144069\teval-rmspe:0.184738\ttrain-rmspe:0.166062\n",
      "[19]\teval-rmse:0.142431\ttrain-rmse:0.142751\teval-rmspe:0.184591\ttrain-rmspe:0.16569\n",
      "[20]\teval-rmse:0.142236\ttrain-rmse:0.142541\teval-rmspe:0.184994\ttrain-rmspe:0.165896\n",
      "[21]\teval-rmse:0.141715\ttrain-rmse:0.142019\teval-rmspe:0.184855\ttrain-rmspe:0.165416\n",
      "[22]\teval-rmse:0.141447\ttrain-rmse:0.14169\teval-rmspe:0.184817\ttrain-rmspe:0.165049\n",
      "[23]\teval-rmse:0.141186\ttrain-rmse:0.141342\teval-rmspe:0.184639\ttrain-rmspe:0.164816\n",
      "[24]\teval-rmse:0.140944\ttrain-rmse:0.141023\teval-rmspe:0.184464\ttrain-rmspe:0.164338\n",
      "[25]\teval-rmse:0.140667\ttrain-rmse:0.140616\teval-rmspe:0.184256\ttrain-rmspe:0.163927\n",
      "[26]\teval-rmse:0.140221\ttrain-rmse:0.139617\teval-rmspe:0.184006\ttrain-rmspe:0.163468\n",
      "[27]\teval-rmse:0.140001\ttrain-rmse:0.139332\teval-rmspe:0.183854\ttrain-rmspe:0.163104\n",
      "[28]\teval-rmse:0.139443\ttrain-rmse:0.138674\teval-rmspe:0.183247\ttrain-rmspe:0.162504\n",
      "[29]\teval-rmse:0.139337\ttrain-rmse:0.138553\teval-rmspe:0.183176\ttrain-rmspe:0.162292\n",
      "[30]\teval-rmse:0.139166\ttrain-rmse:0.138291\teval-rmspe:0.183358\ttrain-rmspe:0.162043\n",
      "[31]\teval-rmse:0.138971\ttrain-rmse:0.138043\teval-rmspe:0.182548\ttrain-rmspe:0.161832\n",
      "[32]\teval-rmse:0.138684\ttrain-rmse:0.137746\teval-rmspe:0.182206\ttrain-rmspe:0.161297\n",
      "[33]\teval-rmse:0.13853\ttrain-rmse:0.137456\teval-rmspe:0.182182\ttrain-rmspe:0.161106\n",
      "[34]\teval-rmse:0.138481\ttrain-rmse:0.137356\teval-rmspe:0.182315\ttrain-rmspe:0.161012\n",
      "[35]\teval-rmse:0.138367\ttrain-rmse:0.137203\teval-rmspe:0.181992\ttrain-rmspe:0.16092\n",
      "[36]\teval-rmse:0.138175\ttrain-rmse:0.136951\teval-rmspe:0.181882\ttrain-rmspe:0.160676\n",
      "[37]\teval-rmse:0.137997\ttrain-rmse:0.136594\teval-rmspe:0.181702\ttrain-rmspe:0.16039\n",
      "[38]\teval-rmse:0.137929\ttrain-rmse:0.136469\teval-rmspe:0.181594\ttrain-rmspe:0.160265\n",
      "[39]\teval-rmse:0.137834\ttrain-rmse:0.136342\teval-rmspe:0.181478\ttrain-rmspe:0.160465\n",
      "[40]\teval-rmse:0.137582\ttrain-rmse:0.135992\teval-rmspe:0.181234\ttrain-rmspe:0.160119\n",
      "[41]\teval-rmse:0.137562\ttrain-rmse:0.13592\teval-rmspe:0.18129\ttrain-rmspe:0.159731\n",
      "[42]\teval-rmse:0.137393\ttrain-rmse:0.135523\teval-rmspe:0.181286\ttrain-rmspe:0.159527\n",
      "[43]\teval-rmse:0.137127\ttrain-rmse:0.135141\teval-rmspe:0.181054\ttrain-rmspe:0.159307\n",
      "[44]\teval-rmse:0.137025\ttrain-rmse:0.135019\teval-rmspe:0.180989\ttrain-rmspe:0.159172\n",
      "[45]\teval-rmse:0.136819\ttrain-rmse:0.134842\teval-rmspe:0.180868\ttrain-rmspe:0.159043\n",
      "[46]\teval-rmse:0.137199\ttrain-rmse:0.134511\teval-rmspe:0.180874\ttrain-rmspe:0.159008\n",
      "[47]\teval-rmse:0.137094\ttrain-rmse:0.134352\teval-rmspe:0.18083\ttrain-rmspe:0.158889\n",
      "[48]\teval-rmse:0.137069\ttrain-rmse:0.134182\teval-rmspe:0.180808\ttrain-rmspe:0.158779\n",
      "[49]\teval-rmse:0.137031\ttrain-rmse:0.134111\teval-rmspe:0.180804\ttrain-rmspe:0.158717\n",
      "[50]\teval-rmse:0.137\ttrain-rmse:0.134053\teval-rmspe:0.180773\ttrain-rmspe:0.158647\n",
      "[51]\teval-rmse:0.136975\ttrain-rmse:0.13399\teval-rmspe:0.180738\ttrain-rmspe:0.158585\n",
      "[52]\teval-rmse:0.136777\ttrain-rmse:0.133797\teval-rmspe:0.180616\ttrain-rmspe:0.158443\n",
      "[53]\teval-rmse:0.136691\ttrain-rmse:0.133636\teval-rmspe:0.18059\ttrain-rmspe:0.15826\n",
      "[54]\teval-rmse:0.136706\ttrain-rmse:0.133619\teval-rmspe:0.180695\ttrain-rmspe:0.158243\n",
      "[55]\teval-rmse:0.136669\ttrain-rmse:0.133526\teval-rmspe:0.180659\ttrain-rmspe:0.15811\n",
      "[56]\teval-rmse:0.136518\ttrain-rmse:0.133305\teval-rmspe:0.180583\ttrain-rmspe:0.158038\n",
      "[57]\teval-rmse:0.136536\ttrain-rmse:0.133161\teval-rmspe:0.180608\ttrain-rmspe:0.157937\n",
      "[58]\teval-rmse:0.136446\ttrain-rmse:0.133042\teval-rmspe:0.180691\ttrain-rmspe:0.157833\n",
      "[59]\teval-rmse:0.136438\ttrain-rmse:0.132928\teval-rmspe:0.180633\ttrain-rmspe:0.157737\n",
      "[60]\teval-rmse:0.136415\ttrain-rmse:0.132783\teval-rmspe:0.180636\ttrain-rmspe:0.157681\n",
      "[61]\teval-rmse:0.136343\ttrain-rmse:0.132694\teval-rmspe:0.180658\ttrain-rmspe:0.157579\n",
      "[62]\teval-rmse:0.136303\ttrain-rmse:0.132612\teval-rmspe:0.180599\ttrain-rmspe:0.15747\n",
      "[63]\teval-rmse:0.13629\ttrain-rmse:0.132551\teval-rmspe:0.180597\ttrain-rmspe:0.157434\n",
      "[64]\teval-rmse:0.136285\ttrain-rmse:0.132434\teval-rmspe:0.18056\ttrain-rmspe:0.157405\n",
      "[65]\teval-rmse:0.136259\ttrain-rmse:0.132276\teval-rmspe:0.180511\ttrain-rmspe:0.157308\n",
      "[66]\teval-rmse:0.136247\ttrain-rmse:0.132133\teval-rmspe:0.180557\ttrain-rmspe:0.157213\n",
      "[67]\teval-rmse:0.136187\ttrain-rmse:0.132057\teval-rmspe:0.180395\ttrain-rmspe:0.157037\n",
      "[68]\teval-rmse:0.136133\ttrain-rmse:0.131986\teval-rmspe:0.180378\ttrain-rmspe:0.156943\n",
      "[69]\teval-rmse:0.136049\ttrain-rmse:0.131871\teval-rmspe:0.180308\ttrain-rmspe:0.156592\n",
      "[70]\teval-rmse:0.136161\ttrain-rmse:0.131826\teval-rmspe:0.180345\ttrain-rmspe:0.156929\n",
      "[71]\teval-rmse:0.13612\ttrain-rmse:0.131775\teval-rmspe:0.180311\ttrain-rmspe:0.156887\n",
      "[72]\teval-rmse:0.136102\ttrain-rmse:0.131725\teval-rmspe:0.180311\ttrain-rmspe:0.156868\n",
      "[73]\teval-rmse:0.136099\ttrain-rmse:0.13157\teval-rmspe:0.180436\ttrain-rmspe:0.156843\n",
      "[74]\teval-rmse:0.136149\ttrain-rmse:0.131486\teval-rmspe:0.180699\ttrain-rmspe:0.156777\n",
      "[75]\teval-rmse:0.136131\ttrain-rmse:0.131451\teval-rmspe:0.180539\ttrain-rmspe:0.156688\n",
      "[76]\teval-rmse:0.136119\ttrain-rmse:0.131319\teval-rmspe:0.180537\ttrain-rmspe:0.156657\n",
      "[77]\teval-rmse:0.136039\ttrain-rmse:0.131117\teval-rmspe:0.180527\ttrain-rmspe:0.156504\n",
      "[78]\teval-rmse:0.136023\ttrain-rmse:0.131096\teval-rmspe:0.180542\ttrain-rmspe:0.156258\n",
      "[79]\teval-rmse:0.136013\ttrain-rmse:0.131039\teval-rmspe:0.180572\ttrain-rmspe:0.15621\n",
      "[80]\teval-rmse:0.13595\ttrain-rmse:0.13097\teval-rmspe:0.180528\ttrain-rmspe:0.156147\n",
      "[81]\teval-rmse:0.135649\ttrain-rmse:0.130912\teval-rmspe:0.180584\ttrain-rmspe:0.155924\n",
      "[82]\teval-rmse:0.135587\ttrain-rmse:0.13082\teval-rmspe:0.180519\ttrain-rmspe:0.155846\n",
      "[83]\teval-rmse:0.135545\ttrain-rmse:0.130746\teval-rmspe:0.180504\ttrain-rmspe:0.155783\n",
      "[84]\teval-rmse:0.135513\ttrain-rmse:0.130692\teval-rmspe:0.180408\ttrain-rmspe:0.15572\n",
      "[85]\teval-rmse:0.135504\ttrain-rmse:0.130653\teval-rmspe:0.180427\ttrain-rmspe:0.155663\n",
      "[86]\teval-rmse:0.135457\ttrain-rmse:0.130521\teval-rmspe:0.180399\ttrain-rmspe:0.155555\n",
      "[87]\teval-rmse:0.135473\ttrain-rmse:0.130501\teval-rmspe:0.180472\ttrain-rmspe:0.15555\n",
      "[88]\teval-rmse:0.135489\ttrain-rmse:0.130479\teval-rmspe:0.180497\ttrain-rmspe:0.15569\n",
      "[89]\teval-rmse:0.13546\ttrain-rmse:0.130437\teval-rmspe:0.180463\ttrain-rmspe:0.155643\n",
      "[90]\teval-rmse:0.135392\ttrain-rmse:0.130348\teval-rmspe:0.180306\ttrain-rmspe:0.155627\n",
      "[91]\teval-rmse:0.135397\ttrain-rmse:0.130318\teval-rmspe:0.180323\ttrain-rmspe:0.1556\n",
      "[92]\teval-rmse:0.13535\ttrain-rmse:0.130297\teval-rmspe:0.180322\ttrain-rmspe:0.155494\n",
      "[93]\teval-rmse:0.135334\ttrain-rmse:0.130273\teval-rmspe:0.180319\ttrain-rmspe:0.155562\n",
      "[94]\teval-rmse:0.135295\ttrain-rmse:0.130203\teval-rmspe:0.180298\ttrain-rmspe:0.155453\n",
      "[95]\teval-rmse:0.135279\ttrain-rmse:0.130175\teval-rmspe:0.18028\ttrain-rmspe:0.155424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96]\teval-rmse:0.135305\ttrain-rmse:0.13017\teval-rmspe:0.180399\ttrain-rmspe:0.155427\n",
      "[97]\teval-rmse:0.135233\ttrain-rmse:0.130054\teval-rmspe:0.180266\ttrain-rmspe:0.155462\n",
      "[98]\teval-rmse:0.13522\ttrain-rmse:0.13002\teval-rmspe:0.180254\ttrain-rmspe:0.155452\n",
      "[99]\teval-rmse:0.135241\ttrain-rmse:0.129811\teval-rmspe:0.180132\ttrain-rmspe:0.1554\n",
      "[100]\teval-rmse:0.135231\ttrain-rmse:0.129741\teval-rmspe:0.180138\ttrain-rmspe:0.155292\n",
      "[101]\teval-rmse:0.135119\ttrain-rmse:0.129602\teval-rmspe:0.18011\ttrain-rmspe:0.155086\n",
      "[102]\teval-rmse:0.135125\ttrain-rmse:0.129562\teval-rmspe:0.180134\ttrain-rmspe:0.155034\n",
      "[103]\teval-rmse:0.135163\ttrain-rmse:0.129521\teval-rmspe:0.180141\ttrain-rmspe:0.155012\n",
      "[104]\teval-rmse:0.135141\ttrain-rmse:0.129473\teval-rmspe:0.180149\ttrain-rmspe:0.154832\n",
      "[105]\teval-rmse:0.13517\ttrain-rmse:0.129459\teval-rmspe:0.180295\ttrain-rmspe:0.154814\n",
      "[106]\teval-rmse:0.135145\ttrain-rmse:0.129351\teval-rmspe:0.180292\ttrain-rmspe:0.1548\n",
      "[107]\teval-rmse:0.135141\ttrain-rmse:0.129323\teval-rmspe:0.180446\ttrain-rmspe:0.154737\n",
      "[108]\teval-rmse:0.135134\ttrain-rmse:0.129248\teval-rmspe:0.180429\ttrain-rmspe:0.154704\n",
      "[109]\teval-rmse:0.135044\ttrain-rmse:0.129145\teval-rmspe:0.180425\ttrain-rmspe:0.154621\n",
      "[110]\teval-rmse:0.134969\ttrain-rmse:0.129027\teval-rmspe:0.180425\ttrain-rmspe:0.154533\n",
      "[111]\teval-rmse:0.134968\ttrain-rmse:0.129001\teval-rmspe:0.18041\ttrain-rmspe:0.154499\n",
      "[112]\teval-rmse:0.13491\ttrain-rmse:0.128923\teval-rmspe:0.180288\ttrain-rmspe:0.154336\n",
      "[113]\teval-rmse:0.134894\ttrain-rmse:0.128836\teval-rmspe:0.180097\ttrain-rmspe:0.154296\n",
      "[114]\teval-rmse:0.134891\ttrain-rmse:0.1288\teval-rmspe:0.180134\ttrain-rmspe:0.154245\n",
      "[115]\teval-rmse:0.134878\ttrain-rmse:0.12869\teval-rmspe:0.18007\ttrain-rmspe:0.154235\n",
      "[116]\teval-rmse:0.134644\ttrain-rmse:0.128633\teval-rmspe:0.180231\ttrain-rmspe:0.154179\n",
      "[117]\teval-rmse:0.13461\ttrain-rmse:0.128592\teval-rmspe:0.180181\ttrain-rmspe:0.154139\n",
      "[118]\teval-rmse:0.134628\ttrain-rmse:0.128474\teval-rmspe:0.180212\ttrain-rmspe:0.154149\n",
      "[119]\teval-rmse:0.134615\ttrain-rmse:0.128394\teval-rmspe:0.180119\ttrain-rmspe:0.15413\n",
      "[120]\teval-rmse:0.134596\ttrain-rmse:0.128274\teval-rmspe:0.180061\ttrain-rmspe:0.154067\n",
      "[121]\teval-rmse:0.134591\ttrain-rmse:0.128206\teval-rmspe:0.180084\ttrain-rmspe:0.154057\n",
      "[122]\teval-rmse:0.134591\ttrain-rmse:0.128189\teval-rmspe:0.180068\ttrain-rmspe:0.154023\n",
      "[123]\teval-rmse:0.134538\ttrain-rmse:0.128115\teval-rmspe:0.180096\ttrain-rmspe:0.153944\n",
      "[124]\teval-rmse:0.134509\ttrain-rmse:0.128085\teval-rmspe:0.180094\ttrain-rmspe:0.153927\n",
      "[125]\teval-rmse:0.134475\ttrain-rmse:0.128016\teval-rmspe:0.179999\ttrain-rmspe:0.153864\n",
      "[126]\teval-rmse:0.134501\ttrain-rmse:0.127979\teval-rmspe:0.180096\ttrain-rmspe:0.136745\n",
      "[127]\teval-rmse:0.134452\ttrain-rmse:0.12792\teval-rmspe:0.180046\ttrain-rmspe:0.136698\n",
      "[128]\teval-rmse:0.134474\ttrain-rmse:0.127804\teval-rmspe:0.180212\ttrain-rmspe:0.137147\n",
      "[129]\teval-rmse:0.134373\ttrain-rmse:0.127647\teval-rmspe:0.179964\ttrain-rmspe:0.13704\n",
      "[130]\teval-rmse:0.134314\ttrain-rmse:0.127576\teval-rmspe:0.179703\ttrain-rmspe:0.136945\n",
      "[131]\teval-rmse:0.134289\ttrain-rmse:0.127527\teval-rmspe:0.179749\ttrain-rmspe:0.136896\n",
      "[132]\teval-rmse:0.13426\ttrain-rmse:0.127332\teval-rmspe:0.179691\ttrain-rmspe:0.136815\n",
      "[133]\teval-rmse:0.134252\ttrain-rmse:0.127307\teval-rmspe:0.179688\ttrain-rmspe:0.13678\n",
      "[134]\teval-rmse:0.134245\ttrain-rmse:0.127192\teval-rmspe:0.179684\ttrain-rmspe:0.136744\n",
      "[135]\teval-rmse:0.134197\ttrain-rmse:0.127154\teval-rmspe:0.179625\ttrain-rmspe:0.136707\n",
      "[136]\teval-rmse:0.134167\ttrain-rmse:0.127104\teval-rmspe:0.179583\ttrain-rmspe:0.136578\n",
      "[137]\teval-rmse:0.134171\ttrain-rmse:0.127019\teval-rmspe:0.179588\ttrain-rmspe:0.137273\n",
      "[138]\teval-rmse:0.134173\ttrain-rmse:0.126973\teval-rmspe:0.179588\ttrain-rmspe:0.137241\n",
      "[139]\teval-rmse:0.134208\ttrain-rmse:0.126957\teval-rmspe:0.179576\ttrain-rmspe:0.137194\n",
      "[140]\teval-rmse:0.134199\ttrain-rmse:0.126934\teval-rmspe:0.179534\ttrain-rmspe:0.137177\n",
      "[141]\teval-rmse:0.134194\ttrain-rmse:0.126783\teval-rmspe:0.179608\ttrain-rmspe:0.137173\n",
      "[142]\teval-rmse:0.134231\ttrain-rmse:0.126681\teval-rmspe:0.179572\ttrain-rmspe:0.137163\n",
      "[143]\teval-rmse:0.134207\ttrain-rmse:0.126548\teval-rmspe:0.179544\ttrain-rmspe:0.137118\n",
      "[144]\teval-rmse:0.134233\ttrain-rmse:0.126535\teval-rmspe:0.179653\ttrain-rmspe:0.137117\n",
      "[145]\teval-rmse:0.134223\ttrain-rmse:0.126452\teval-rmspe:0.179654\ttrain-rmspe:0.137034\n",
      "[146]\teval-rmse:0.134247\ttrain-rmse:0.126441\teval-rmspe:0.179776\ttrain-rmspe:0.137019\n",
      "[147]\teval-rmse:0.13425\ttrain-rmse:0.126419\teval-rmspe:0.179955\ttrain-rmspe:0.13699\n",
      "[148]\teval-rmse:0.13422\ttrain-rmse:0.126385\teval-rmspe:0.179898\ttrain-rmspe:0.136948\n",
      "[149]\teval-rmse:0.134208\ttrain-rmse:0.126346\teval-rmspe:0.179879\ttrain-rmspe:0.136897\n",
      "[150]\teval-rmse:0.134216\ttrain-rmse:0.126336\teval-rmspe:0.179876\ttrain-rmspe:0.13688\n",
      "[151]\teval-rmse:0.134214\ttrain-rmse:0.126315\teval-rmspe:0.179894\ttrain-rmspe:0.136839\n",
      "[152]\teval-rmse:0.134203\ttrain-rmse:0.126224\teval-rmspe:0.1799\ttrain-rmspe:0.136803\n",
      "[153]\teval-rmse:0.134137\ttrain-rmse:0.126143\teval-rmspe:0.179852\ttrain-rmspe:0.136722\n",
      "[154]\teval-rmse:0.134147\ttrain-rmse:0.126121\teval-rmspe:0.179923\ttrain-rmspe:0.136719\n",
      "[155]\teval-rmse:0.134109\ttrain-rmse:0.126068\teval-rmspe:0.179903\ttrain-rmspe:0.136662\n",
      "[156]\teval-rmse:0.134076\ttrain-rmse:0.125976\teval-rmspe:0.179801\ttrain-rmspe:0.136631\n",
      "[157]\teval-rmse:0.134072\ttrain-rmse:0.12591\teval-rmspe:0.179791\ttrain-rmspe:0.136566\n",
      "[158]\teval-rmse:0.133983\ttrain-rmse:0.125802\teval-rmspe:0.179489\ttrain-rmspe:0.136463\n",
      "[159]\teval-rmse:0.133916\ttrain-rmse:0.125702\teval-rmspe:0.179223\ttrain-rmspe:0.136321\n",
      "[160]\teval-rmse:0.133869\ttrain-rmse:0.125638\teval-rmspe:0.179141\ttrain-rmspe:0.13624\n",
      "[161]\teval-rmse:0.133841\ttrain-rmse:0.125569\teval-rmspe:0.179037\ttrain-rmspe:0.136206\n",
      "[162]\teval-rmse:0.133773\ttrain-rmse:0.125475\teval-rmspe:0.179012\ttrain-rmspe:0.136131\n",
      "[163]\teval-rmse:0.133756\ttrain-rmse:0.125442\teval-rmspe:0.178988\ttrain-rmspe:0.136086\n",
      "[164]\teval-rmse:0.13368\ttrain-rmse:0.125337\teval-rmspe:0.178876\ttrain-rmspe:0.135919\n",
      "[165]\teval-rmse:0.13368\ttrain-rmse:0.125313\teval-rmspe:0.178871\ttrain-rmspe:0.134925\n",
      "[166]\teval-rmse:0.133682\ttrain-rmse:0.125284\teval-rmspe:0.178887\ttrain-rmspe:0.134861\n",
      "[167]\teval-rmse:0.133674\ttrain-rmse:0.125249\teval-rmspe:0.17879\ttrain-rmspe:0.13482\n",
      "[168]\teval-rmse:0.133673\ttrain-rmse:0.125246\teval-rmspe:0.178824\ttrain-rmspe:0.134804\n",
      "[169]\teval-rmse:0.133587\ttrain-rmse:0.12509\teval-rmspe:0.178405\ttrain-rmspe:0.1347\n",
      "[170]\teval-rmse:0.133573\ttrain-rmse:0.125061\teval-rmspe:0.178368\ttrain-rmspe:0.134637\n",
      "[171]\teval-rmse:0.133599\ttrain-rmse:0.125018\teval-rmspe:0.178384\ttrain-rmspe:0.134293\n",
      "[172]\teval-rmse:0.133545\ttrain-rmse:0.124981\teval-rmspe:0.178166\ttrain-rmspe:0.13425\n",
      "[173]\teval-rmse:0.133501\ttrain-rmse:0.124916\teval-rmspe:0.178166\ttrain-rmspe:0.134254\n",
      "[174]\teval-rmse:0.133506\ttrain-rmse:0.124868\teval-rmspe:0.178236\ttrain-rmspe:0.134172\n",
      "[175]\teval-rmse:0.133458\ttrain-rmse:0.124794\teval-rmspe:0.178121\ttrain-rmspe:0.134072\n",
      "[176]\teval-rmse:0.133507\ttrain-rmse:0.124754\teval-rmspe:0.178141\ttrain-rmspe:0.134057\n",
      "[177]\teval-rmse:0.133494\ttrain-rmse:0.124603\teval-rmspe:0.17812\ttrain-rmspe:0.133968\n",
      "[178]\teval-rmse:0.133473\ttrain-rmse:0.124545\teval-rmspe:0.178119\ttrain-rmspe:0.133905\n",
      "[179]\teval-rmse:0.133332\ttrain-rmse:0.124472\teval-rmspe:0.178242\ttrain-rmspe:0.133836\n",
      "[180]\teval-rmse:0.133336\ttrain-rmse:0.124442\teval-rmspe:0.178252\ttrain-rmspe:0.133755\n",
      "[181]\teval-rmse:0.133347\ttrain-rmse:0.124434\teval-rmspe:0.178307\ttrain-rmspe:0.133735\n",
      "[182]\teval-rmse:0.133329\ttrain-rmse:0.124389\teval-rmspe:0.178289\ttrain-rmspe:0.133718\n",
      "[183]\teval-rmse:0.133306\ttrain-rmse:0.124333\teval-rmspe:0.177854\ttrain-rmspe:0.133681\n",
      "[184]\teval-rmse:0.133304\ttrain-rmse:0.124315\teval-rmspe:0.177846\ttrain-rmspe:0.133667\n",
      "[185]\teval-rmse:0.133263\ttrain-rmse:0.124242\teval-rmspe:0.177822\ttrain-rmspe:0.133603\n",
      "[186]\teval-rmse:0.133254\ttrain-rmse:0.124235\teval-rmspe:0.177778\ttrain-rmspe:0.133585\n",
      "[187]\teval-rmse:0.133259\ttrain-rmse:0.124224\teval-rmspe:0.177833\ttrain-rmspe:0.13392\n",
      "[188]\teval-rmse:0.133228\ttrain-rmse:0.124191\teval-rmspe:0.177811\ttrain-rmspe:0.133885\n",
      "[189]\teval-rmse:0.133197\ttrain-rmse:0.12415\teval-rmspe:0.177786\ttrain-rmspe:0.133842\n",
      "[190]\teval-rmse:0.133196\ttrain-rmse:0.124114\teval-rmspe:0.177804\ttrain-rmspe:0.133792\n",
      "[191]\teval-rmse:0.13317\ttrain-rmse:0.124079\teval-rmspe:0.177775\ttrain-rmspe:0.133731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192]\teval-rmse:0.133165\ttrain-rmse:0.124061\teval-rmspe:0.177761\ttrain-rmspe:0.133691\n",
      "[193]\teval-rmse:0.133133\ttrain-rmse:0.124052\teval-rmspe:0.177681\ttrain-rmspe:0.133678\n",
      "[194]\teval-rmse:0.133121\ttrain-rmse:0.124045\teval-rmspe:0.177704\ttrain-rmspe:0.13367\n",
      "[195]\teval-rmse:0.13312\ttrain-rmse:0.123998\teval-rmspe:0.177663\ttrain-rmspe:0.133631\n",
      "[196]\teval-rmse:0.133096\ttrain-rmse:0.123976\teval-rmspe:0.177652\ttrain-rmspe:0.133619\n",
      "[197]\teval-rmse:0.133081\ttrain-rmse:0.123928\teval-rmspe:0.177721\ttrain-rmspe:0.133594\n",
      "[198]\teval-rmse:0.133055\ttrain-rmse:0.12388\teval-rmspe:0.177699\ttrain-rmspe:0.133571\n",
      "[199]\teval-rmse:0.133053\ttrain-rmse:0.123855\teval-rmspe:0.177763\ttrain-rmspe:0.133581\n",
      "[200]\teval-rmse:0.133025\ttrain-rmse:0.123821\teval-rmspe:0.177719\ttrain-rmspe:0.133564\n",
      "[201]\teval-rmse:0.132987\ttrain-rmse:0.123756\teval-rmspe:0.177695\ttrain-rmspe:0.133506\n",
      "[202]\teval-rmse:0.132978\ttrain-rmse:0.123706\teval-rmspe:0.17768\ttrain-rmspe:0.133488\n",
      "[203]\teval-rmse:0.132973\ttrain-rmse:0.123649\teval-rmspe:0.177655\ttrain-rmspe:0.133423\n",
      "[204]\teval-rmse:0.132972\ttrain-rmse:0.123616\teval-rmspe:0.177646\ttrain-rmspe:0.133383\n",
      "[205]\teval-rmse:0.132968\ttrain-rmse:0.123563\teval-rmspe:0.177684\ttrain-rmspe:0.133366\n",
      "[206]\teval-rmse:0.132964\ttrain-rmse:0.12355\teval-rmspe:0.177694\ttrain-rmspe:0.133353\n",
      "[207]\teval-rmse:0.132954\ttrain-rmse:0.123523\teval-rmspe:0.177672\ttrain-rmspe:0.133212\n",
      "[208]\teval-rmse:0.132937\ttrain-rmse:0.123526\teval-rmspe:0.177649\ttrain-rmspe:0.133206\n",
      "[209]\teval-rmse:0.132929\ttrain-rmse:0.12351\teval-rmspe:0.177654\ttrain-rmspe:0.133184\n",
      "[210]\teval-rmse:0.132965\ttrain-rmse:0.123491\teval-rmspe:0.177812\ttrain-rmspe:0.133148\n",
      "[211]\teval-rmse:0.132937\ttrain-rmse:0.123445\teval-rmspe:0.177766\ttrain-rmspe:0.133089\n",
      "[212]\teval-rmse:0.13292\ttrain-rmse:0.123417\teval-rmspe:0.177797\ttrain-rmspe:0.133059\n",
      "[213]\teval-rmse:0.13293\ttrain-rmse:0.123371\teval-rmspe:0.17785\ttrain-rmspe:0.133028\n",
      "[214]\teval-rmse:0.132906\ttrain-rmse:0.123339\teval-rmspe:0.177839\ttrain-rmspe:0.132773\n",
      "[215]\teval-rmse:0.132904\ttrain-rmse:0.1233\teval-rmspe:0.177629\ttrain-rmspe:0.132742\n",
      "[216]\teval-rmse:0.13292\ttrain-rmse:0.123278\teval-rmspe:0.177671\ttrain-rmspe:0.13272\n",
      "[217]\teval-rmse:0.132918\ttrain-rmse:0.123267\teval-rmspe:0.177645\ttrain-rmspe:0.132705\n",
      "[218]\teval-rmse:0.132911\ttrain-rmse:0.123243\teval-rmspe:0.177642\ttrain-rmspe:0.132681\n",
      "[219]\teval-rmse:0.132914\ttrain-rmse:0.123206\teval-rmspe:0.177645\ttrain-rmspe:0.132613\n",
      "[220]\teval-rmse:0.133118\ttrain-rmse:0.1232\teval-rmspe:0.177672\ttrain-rmspe:0.132639\n",
      "[221]\teval-rmse:0.13315\ttrain-rmse:0.123191\teval-rmspe:0.177721\ttrain-rmspe:0.132635\n",
      "[222]\teval-rmse:0.133173\ttrain-rmse:0.123189\teval-rmspe:0.177814\ttrain-rmspe:0.132636\n",
      "[223]\teval-rmse:0.133159\ttrain-rmse:0.123181\teval-rmspe:0.177831\ttrain-rmspe:0.132611\n",
      "[224]\teval-rmse:0.13317\ttrain-rmse:0.123172\teval-rmspe:0.17784\ttrain-rmspe:0.132917\n",
      "[225]\teval-rmse:0.133159\ttrain-rmse:0.12312\teval-rmspe:0.177974\ttrain-rmspe:0.13284\n",
      "[226]\teval-rmse:0.133171\ttrain-rmse:0.12311\teval-rmspe:0.177991\ttrain-rmspe:0.132806\n",
      "[227]\teval-rmse:0.133167\ttrain-rmse:0.123105\teval-rmspe:0.178011\ttrain-rmspe:0.132788\n",
      "[228]\teval-rmse:0.133173\ttrain-rmse:0.123048\teval-rmspe:0.177933\ttrain-rmspe:0.132756\n",
      "[229]\teval-rmse:0.133175\ttrain-rmse:0.123027\teval-rmspe:0.177921\ttrain-rmspe:0.132723\n",
      "[230]\teval-rmse:0.133153\ttrain-rmse:0.122987\teval-rmspe:0.177918\ttrain-rmspe:0.132643\n",
      "[231]\teval-rmse:0.133136\ttrain-rmse:0.122961\teval-rmspe:0.177797\ttrain-rmspe:0.132616\n",
      "[232]\teval-rmse:0.133123\ttrain-rmse:0.122939\teval-rmspe:0.177773\ttrain-rmspe:0.132598\n",
      "[233]\teval-rmse:0.13315\ttrain-rmse:0.122928\teval-rmspe:0.177884\ttrain-rmspe:0.132573\n",
      "[234]\teval-rmse:0.133156\ttrain-rmse:0.122903\teval-rmspe:0.17788\ttrain-rmspe:0.13254\n",
      "[235]\teval-rmse:0.133157\ttrain-rmse:0.122878\teval-rmspe:0.177934\ttrain-rmspe:0.132509\n",
      "[236]\teval-rmse:0.133144\ttrain-rmse:0.122853\teval-rmspe:0.17795\ttrain-rmspe:0.132476\n",
      "[237]\teval-rmse:0.133145\ttrain-rmse:0.122846\teval-rmspe:0.17797\ttrain-rmspe:0.132467\n",
      "[238]\teval-rmse:0.133119\ttrain-rmse:0.122837\teval-rmspe:0.177964\ttrain-rmspe:0.132424\n",
      "[239]\teval-rmse:0.133105\ttrain-rmse:0.12283\teval-rmspe:0.177888\ttrain-rmspe:0.132406\n",
      "[240]\teval-rmse:0.133141\ttrain-rmse:0.122816\teval-rmspe:0.178178\ttrain-rmspe:0.132356\n",
      "[241]\teval-rmse:0.133157\ttrain-rmse:0.122806\teval-rmspe:0.178248\ttrain-rmspe:0.13236\n",
      "[242]\teval-rmse:0.133142\ttrain-rmse:0.122783\teval-rmspe:0.178223\ttrain-rmspe:0.132331\n",
      "[243]\teval-rmse:0.133163\ttrain-rmse:0.122747\teval-rmspe:0.17833\ttrain-rmspe:0.132314\n",
      "[244]\teval-rmse:0.13315\ttrain-rmse:0.122732\teval-rmspe:0.178343\ttrain-rmspe:0.132297\n",
      "[245]\teval-rmse:0.133153\ttrain-rmse:0.122689\teval-rmspe:0.178314\ttrain-rmspe:0.13226\n",
      "[246]\teval-rmse:0.13316\ttrain-rmse:0.122676\teval-rmspe:0.178324\ttrain-rmspe:0.132602\n",
      "[247]\teval-rmse:0.133173\ttrain-rmse:0.122668\teval-rmspe:0.178421\ttrain-rmspe:0.132598\n",
      "[248]\teval-rmse:0.133181\ttrain-rmse:0.122642\teval-rmspe:0.178449\ttrain-rmspe:0.132558\n",
      "[249]\teval-rmse:0.13319\ttrain-rmse:0.122576\teval-rmspe:0.17849\ttrain-rmspe:0.132525\n",
      "[250]\teval-rmse:0.133571\ttrain-rmse:0.122473\teval-rmspe:0.178599\ttrain-rmspe:0.132499\n",
      "[251]\teval-rmse:0.133585\ttrain-rmse:0.122453\teval-rmspe:0.178647\ttrain-rmspe:0.13246\n",
      "[252]\teval-rmse:0.133561\ttrain-rmse:0.122428\teval-rmspe:0.178606\ttrain-rmspe:0.132019\n",
      "[253]\teval-rmse:0.133574\ttrain-rmse:0.122361\teval-rmspe:0.178612\ttrain-rmspe:0.132011\n",
      "[254]\teval-rmse:0.133713\ttrain-rmse:0.12231\teval-rmspe:0.178484\ttrain-rmspe:0.131453\n",
      "[255]\teval-rmse:0.133702\ttrain-rmse:0.122291\teval-rmspe:0.178475\ttrain-rmspe:0.131426\n",
      "[256]\teval-rmse:0.133708\ttrain-rmse:0.122287\teval-rmspe:0.178493\ttrain-rmspe:0.131417\n",
      "[257]\teval-rmse:0.133712\ttrain-rmse:0.1222\teval-rmspe:0.178521\ttrain-rmspe:0.131401\n",
      "[258]\teval-rmse:0.133697\ttrain-rmse:0.122183\teval-rmspe:0.178535\ttrain-rmspe:0.131385\n",
      "[259]\teval-rmse:0.133713\ttrain-rmse:0.122206\teval-rmspe:0.178542\ttrain-rmspe:0.13136\n",
      "[260]\teval-rmse:0.13372\ttrain-rmse:0.122201\teval-rmspe:0.178602\ttrain-rmspe:0.131375\n",
      "[261]\teval-rmse:0.133739\ttrain-rmse:0.122109\teval-rmspe:0.178624\ttrain-rmspe:0.131354\n",
      "[262]\teval-rmse:0.133754\ttrain-rmse:0.122093\teval-rmspe:0.178612\ttrain-rmspe:0.131323\n",
      "[263]\teval-rmse:0.133751\ttrain-rmse:0.122082\teval-rmspe:0.17861\ttrain-rmspe:0.131314\n",
      "[264]\teval-rmse:0.133749\ttrain-rmse:0.121974\teval-rmspe:0.178651\ttrain-rmspe:0.131268\n",
      "[265]\teval-rmse:0.133768\ttrain-rmse:0.12189\teval-rmspe:0.178641\ttrain-rmspe:0.131209\n",
      "[266]\teval-rmse:0.133772\ttrain-rmse:0.121871\teval-rmspe:0.178688\ttrain-rmspe:0.131179\n",
      "[267]\teval-rmse:0.133761\ttrain-rmse:0.121832\teval-rmspe:0.178654\ttrain-rmspe:0.131145\n",
      "[268]\teval-rmse:0.133744\ttrain-rmse:0.121808\teval-rmspe:0.178809\ttrain-rmspe:0.131133\n",
      "[269]\teval-rmse:0.133715\ttrain-rmse:0.121802\teval-rmspe:0.178773\ttrain-rmspe:0.131147\n",
      "[270]\teval-rmse:0.133734\ttrain-rmse:0.121798\teval-rmspe:0.178866\ttrain-rmspe:0.131138\n",
      "[271]\teval-rmse:0.13374\ttrain-rmse:0.121781\teval-rmspe:0.178874\ttrain-rmspe:0.131064\n",
      "[272]\teval-rmse:0.133748\ttrain-rmse:0.121725\teval-rmspe:0.178823\ttrain-rmspe:0.130998\n",
      "[273]\teval-rmse:0.133733\ttrain-rmse:0.121705\teval-rmspe:0.178799\ttrain-rmspe:0.130961\n",
      "[274]\teval-rmse:0.133736\ttrain-rmse:0.121646\teval-rmspe:0.178931\ttrain-rmspe:0.130924\n",
      "[275]\teval-rmse:0.133718\ttrain-rmse:0.121623\teval-rmspe:0.178911\ttrain-rmspe:0.130879\n",
      "[276]\teval-rmse:0.133695\ttrain-rmse:0.121585\teval-rmspe:0.178887\ttrain-rmspe:0.130836\n",
      "[277]\teval-rmse:0.133694\ttrain-rmse:0.121558\teval-rmspe:0.178884\ttrain-rmspe:0.130824\n",
      "[278]\teval-rmse:0.133693\ttrain-rmse:0.1215\teval-rmspe:0.179103\ttrain-rmspe:0.130795\n",
      "[279]\teval-rmse:0.13365\ttrain-rmse:0.121494\teval-rmspe:0.178924\ttrain-rmspe:0.130787\n",
      "[280]\teval-rmse:0.133628\ttrain-rmse:0.121443\teval-rmspe:0.178911\ttrain-rmspe:0.130742\n",
      "[281]\teval-rmse:0.133616\ttrain-rmse:0.121396\teval-rmspe:0.178905\ttrain-rmspe:0.130726\n",
      "[282]\teval-rmse:0.133612\ttrain-rmse:0.121375\teval-rmspe:0.178912\ttrain-rmspe:0.130564\n",
      "[283]\teval-rmse:0.133597\ttrain-rmse:0.121355\teval-rmspe:0.17887\ttrain-rmspe:0.130537\n",
      "[284]\teval-rmse:0.133574\ttrain-rmse:0.121307\teval-rmspe:0.17886\ttrain-rmspe:0.130468\n",
      "[285]\teval-rmse:0.133578\ttrain-rmse:0.121276\teval-rmspe:0.178796\ttrain-rmspe:0.130444\n",
      "[286]\teval-rmse:0.133612\ttrain-rmse:0.121263\teval-rmspe:0.178825\ttrain-rmspe:0.130881\n",
      "[287]\teval-rmse:0.133607\ttrain-rmse:0.121261\teval-rmspe:0.178797\ttrain-rmspe:0.130856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288]\teval-rmse:0.133639\ttrain-rmse:0.121241\teval-rmspe:0.178809\ttrain-rmspe:0.131312\n",
      "[289]\teval-rmse:0.133648\ttrain-rmse:0.121226\teval-rmspe:0.178841\ttrain-rmspe:0.131325\n",
      "[290]\teval-rmse:0.133653\ttrain-rmse:0.121206\teval-rmspe:0.17885\ttrain-rmspe:0.131318\n",
      "[291]\teval-rmse:0.13365\ttrain-rmse:0.121201\teval-rmspe:0.178854\ttrain-rmspe:0.131308\n",
      "[292]\teval-rmse:0.133633\ttrain-rmse:0.12118\teval-rmspe:0.178699\ttrain-rmspe:0.131269\n",
      "[293]\teval-rmse:0.133632\ttrain-rmse:0.121159\teval-rmspe:0.178684\ttrain-rmspe:0.131243\n",
      "[294]\teval-rmse:0.133711\ttrain-rmse:0.121137\teval-rmspe:0.178797\ttrain-rmspe:0.131219\n",
      "[295]\teval-rmse:0.133633\ttrain-rmse:0.121096\teval-rmspe:0.178793\ttrain-rmspe:0.131208\n",
      "[296]\teval-rmse:0.133626\ttrain-rmse:0.121088\teval-rmspe:0.178715\ttrain-rmspe:0.131204\n",
      "[297]\teval-rmse:0.133617\ttrain-rmse:0.121044\teval-rmspe:0.178723\ttrain-rmspe:0.131184\n",
      "[298]\teval-rmse:0.133652\ttrain-rmse:0.121028\teval-rmspe:0.178736\ttrain-rmspe:0.13112\n",
      "[299]\teval-rmse:0.133637\ttrain-rmse:0.120943\teval-rmspe:0.178703\ttrain-rmspe:0.132044\n",
      "[300]\teval-rmse:0.133706\ttrain-rmse:0.120916\teval-rmspe:0.178719\ttrain-rmspe:0.132033\n",
      "[301]\teval-rmse:0.133682\ttrain-rmse:0.120897\teval-rmspe:0.178698\ttrain-rmspe:0.132013\n",
      "[302]\teval-rmse:0.133676\ttrain-rmse:0.120877\teval-rmspe:0.178691\ttrain-rmspe:0.131974\n",
      "[303]\teval-rmse:0.133699\ttrain-rmse:0.120854\teval-rmspe:0.178841\ttrain-rmspe:0.131948\n",
      "[304]\teval-rmse:0.133698\ttrain-rmse:0.120836\teval-rmspe:0.178841\ttrain-rmspe:0.131321\n",
      "[305]\teval-rmse:0.133713\ttrain-rmse:0.120804\teval-rmspe:0.178917\ttrain-rmspe:0.130365\n",
      "[306]\teval-rmse:0.133704\ttrain-rmse:0.120737\teval-rmspe:0.178886\ttrain-rmspe:0.130318\n",
      "[307]\teval-rmse:0.133712\ttrain-rmse:0.120723\teval-rmspe:0.178885\ttrain-rmspe:0.130303\n",
      "[308]\teval-rmse:0.133693\ttrain-rmse:0.120704\teval-rmspe:0.178859\ttrain-rmspe:0.13029\n",
      "[309]\teval-rmse:0.133687\ttrain-rmse:0.12068\teval-rmspe:0.178851\ttrain-rmspe:0.130247\n",
      "[310]\teval-rmse:0.133632\ttrain-rmse:0.12058\teval-rmspe:0.178818\ttrain-rmspe:0.130059\n",
      "[311]\teval-rmse:0.133639\ttrain-rmse:0.120557\teval-rmspe:0.178828\ttrain-rmspe:0.130034\n",
      "[312]\teval-rmse:0.133631\ttrain-rmse:0.120519\teval-rmspe:0.178837\ttrain-rmspe:0.13001\n",
      "[313]\teval-rmse:0.133612\ttrain-rmse:0.120488\teval-rmspe:0.178835\ttrain-rmspe:0.129977\n",
      "[314]\teval-rmse:0.133624\ttrain-rmse:0.12049\teval-rmspe:0.178859\ttrain-rmspe:0.129966\n",
      "[315]\teval-rmse:0.133639\ttrain-rmse:0.120437\teval-rmspe:0.178864\ttrain-rmspe:0.129984\n",
      "[316]\teval-rmse:0.133632\ttrain-rmse:0.120407\teval-rmspe:0.178831\ttrain-rmspe:0.129939\n",
      "[317]\teval-rmse:0.133646\ttrain-rmse:0.120402\teval-rmspe:0.178863\ttrain-rmspe:0.129916\n",
      "[318]\teval-rmse:0.133646\ttrain-rmse:0.120393\teval-rmspe:0.178836\ttrain-rmspe:0.129839\n",
      "[319]\teval-rmse:0.133652\ttrain-rmse:0.120385\teval-rmspe:0.178854\ttrain-rmspe:0.129822\n",
      "[320]\teval-rmse:0.133634\ttrain-rmse:0.120377\teval-rmspe:0.178797\ttrain-rmspe:0.129818\n",
      "[321]\teval-rmse:0.133618\ttrain-rmse:0.12037\teval-rmspe:0.178765\ttrain-rmspe:0.129807\n",
      "[322]\teval-rmse:0.133614\ttrain-rmse:0.12033\teval-rmspe:0.178766\ttrain-rmspe:0.129792\n",
      "[323]\teval-rmse:0.133663\ttrain-rmse:0.120309\teval-rmspe:0.178755\ttrain-rmspe:0.12978\n",
      "[324]\teval-rmse:0.133666\ttrain-rmse:0.120308\teval-rmspe:0.178761\ttrain-rmspe:0.129771\n",
      "[325]\teval-rmse:0.133682\ttrain-rmse:0.120236\teval-rmspe:0.17875\ttrain-rmspe:0.129722\n",
      "[326]\teval-rmse:0.133697\ttrain-rmse:0.12021\teval-rmspe:0.178786\ttrain-rmspe:0.129659\n",
      "[327]\teval-rmse:0.133714\ttrain-rmse:0.120126\teval-rmspe:0.178796\ttrain-rmspe:0.129626\n",
      "[328]\teval-rmse:0.133941\ttrain-rmse:0.120106\teval-rmspe:0.178876\ttrain-rmspe:0.129585\n",
      "[329]\teval-rmse:0.133929\ttrain-rmse:0.12009\teval-rmspe:0.178836\ttrain-rmspe:0.129491\n",
      "[330]\teval-rmse:0.133935\ttrain-rmse:0.12006\teval-rmspe:0.178848\ttrain-rmspe:0.129478\n",
      "[331]\teval-rmse:0.133929\ttrain-rmse:0.120047\teval-rmspe:0.178839\ttrain-rmspe:0.129459\n",
      "[332]\teval-rmse:0.133882\ttrain-rmse:0.119997\teval-rmspe:0.178844\ttrain-rmspe:0.129405\n",
      "[333]\teval-rmse:0.133872\ttrain-rmse:0.119992\teval-rmspe:0.17884\ttrain-rmspe:0.129402\n",
      "[334]\teval-rmse:0.133871\ttrain-rmse:0.119961\teval-rmspe:0.178837\ttrain-rmspe:0.129368\n",
      "[335]\teval-rmse:0.133869\ttrain-rmse:0.119943\teval-rmspe:0.178831\ttrain-rmspe:0.129349\n",
      "[336]\teval-rmse:0.133852\ttrain-rmse:0.119912\teval-rmspe:0.178806\ttrain-rmspe:0.12932\n",
      "[337]\teval-rmse:0.133873\ttrain-rmse:0.119902\teval-rmspe:0.178831\ttrain-rmspe:0.129282\n",
      "[338]\teval-rmse:0.133868\ttrain-rmse:0.11987\teval-rmspe:0.178833\ttrain-rmspe:0.129243\n",
      "[339]\teval-rmse:0.133857\ttrain-rmse:0.119852\teval-rmspe:0.178882\ttrain-rmspe:0.129215\n",
      "[340]\teval-rmse:0.133862\ttrain-rmse:0.119844\teval-rmspe:0.178738\ttrain-rmspe:0.129203\n",
      "[341]\teval-rmse:0.134334\ttrain-rmse:0.119776\teval-rmspe:0.178773\ttrain-rmspe:0.129193\n",
      "[342]\teval-rmse:0.134363\ttrain-rmse:0.119728\teval-rmspe:0.178774\ttrain-rmspe:0.129185\n",
      "[343]\teval-rmse:0.134375\ttrain-rmse:0.119714\teval-rmspe:0.178778\ttrain-rmspe:0.129169\n",
      "[344]\teval-rmse:0.134377\ttrain-rmse:0.119665\teval-rmspe:0.178781\ttrain-rmspe:0.129141\n",
      "[345]\teval-rmse:0.134385\ttrain-rmse:0.119669\teval-rmspe:0.178795\ttrain-rmspe:0.12914\n",
      "[346]\teval-rmse:0.134359\ttrain-rmse:0.119644\teval-rmspe:0.178778\ttrain-rmspe:0.129113\n",
      "[347]\teval-rmse:0.134367\ttrain-rmse:0.119651\teval-rmspe:0.178819\ttrain-rmspe:0.129113\n",
      "[348]\teval-rmse:0.134364\ttrain-rmse:0.119649\teval-rmspe:0.178783\ttrain-rmspe:0.129112\n",
      "[349]\teval-rmse:0.134367\ttrain-rmse:0.119636\teval-rmspe:0.178811\ttrain-rmspe:0.129109\n",
      "[350]\teval-rmse:0.134369\ttrain-rmse:0.1196\teval-rmspe:0.178866\ttrain-rmspe:0.129075\n",
      "[351]\teval-rmse:0.134358\ttrain-rmse:0.119596\teval-rmspe:0.178865\ttrain-rmspe:0.12907\n",
      "[352]\teval-rmse:0.134352\ttrain-rmse:0.119576\teval-rmspe:0.178886\ttrain-rmspe:0.129054\n",
      "[353]\teval-rmse:0.134357\ttrain-rmse:0.119568\teval-rmspe:0.178905\ttrain-rmspe:0.129046\n",
      "[354]\teval-rmse:0.134343\ttrain-rmse:0.11954\teval-rmspe:0.178896\ttrain-rmspe:0.12901\n",
      "[355]\teval-rmse:0.134332\ttrain-rmse:0.119476\teval-rmspe:0.17893\ttrain-rmspe:0.128999\n",
      "[356]\teval-rmse:0.134254\ttrain-rmse:0.119431\teval-rmspe:0.178889\ttrain-rmspe:0.128979\n",
      "[357]\teval-rmse:0.134241\ttrain-rmse:0.119419\teval-rmspe:0.178862\ttrain-rmspe:0.129549\n",
      "[358]\teval-rmse:0.134228\ttrain-rmse:0.119399\teval-rmspe:0.178816\ttrain-rmspe:0.129506\n",
      "[359]\teval-rmse:0.13423\ttrain-rmse:0.119388\teval-rmspe:0.178825\ttrain-rmspe:0.129498\n",
      "[360]\teval-rmse:0.134199\ttrain-rmse:0.119351\teval-rmspe:0.178796\ttrain-rmspe:0.129448\n",
      "[361]\teval-rmse:0.13421\ttrain-rmse:0.119347\teval-rmspe:0.178837\ttrain-rmspe:0.129441\n",
      "[362]\teval-rmse:0.134182\ttrain-rmse:0.11926\teval-rmspe:0.178852\ttrain-rmspe:0.129392\n",
      "[363]\teval-rmse:0.134182\ttrain-rmse:0.119225\teval-rmspe:0.178817\ttrain-rmspe:0.129369\n",
      "[364]\teval-rmse:0.13417\ttrain-rmse:0.119211\teval-rmspe:0.178747\ttrain-rmspe:0.129348\n",
      "[365]\teval-rmse:0.134167\ttrain-rmse:0.119172\teval-rmspe:0.178756\ttrain-rmspe:0.129323\n",
      "[366]\teval-rmse:0.13415\ttrain-rmse:0.119143\teval-rmspe:0.178791\ttrain-rmspe:0.129092\n",
      "[367]\teval-rmse:0.134164\ttrain-rmse:0.119115\teval-rmspe:0.178878\ttrain-rmspe:0.129056\n",
      "[368]\teval-rmse:0.134129\ttrain-rmse:0.11908\teval-rmspe:0.178741\ttrain-rmspe:0.129856\n",
      "[369]\teval-rmse:0.13411\ttrain-rmse:0.119033\teval-rmspe:0.178752\ttrain-rmspe:0.12982\n",
      "[370]\teval-rmse:0.134127\ttrain-rmse:0.118992\teval-rmspe:0.178822\ttrain-rmspe:0.129817\n",
      "[371]\teval-rmse:0.134133\ttrain-rmse:0.118971\teval-rmspe:0.178831\ttrain-rmspe:0.129753\n",
      "[372]\teval-rmse:0.134135\ttrain-rmse:0.118916\teval-rmspe:0.178925\ttrain-rmspe:0.129672\n",
      "[373]\teval-rmse:0.134171\ttrain-rmse:0.118897\teval-rmspe:0.179247\ttrain-rmspe:0.129637\n",
      "[374]\teval-rmse:0.134164\ttrain-rmse:0.118839\teval-rmspe:0.179244\ttrain-rmspe:0.129603\n",
      "[375]\teval-rmse:0.134166\ttrain-rmse:0.11881\teval-rmspe:0.179234\ttrain-rmspe:0.129607\n",
      "[376]\teval-rmse:0.134167\ttrain-rmse:0.118788\teval-rmspe:0.17921\ttrain-rmspe:0.129593\n",
      "[377]\teval-rmse:0.134179\ttrain-rmse:0.118761\teval-rmspe:0.17925\ttrain-rmspe:0.129587\n",
      "[378]\teval-rmse:0.134185\ttrain-rmse:0.118759\teval-rmspe:0.179265\ttrain-rmspe:0.129578\n",
      "[379]\teval-rmse:0.134202\ttrain-rmse:0.118731\teval-rmspe:0.179458\ttrain-rmspe:0.129557\n",
      "[380]\teval-rmse:0.134173\ttrain-rmse:0.118736\teval-rmspe:0.179475\ttrain-rmspe:0.129573\n",
      "[381]\teval-rmse:0.134181\ttrain-rmse:0.118666\teval-rmspe:0.17954\ttrain-rmspe:0.129572\n",
      "[382]\teval-rmse:0.134161\ttrain-rmse:0.118638\teval-rmspe:0.179541\ttrain-rmspe:0.129506\n",
      "[383]\teval-rmse:0.134148\ttrain-rmse:0.118599\teval-rmspe:0.179508\ttrain-rmspe:0.129474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[384]\teval-rmse:0.13414\ttrain-rmse:0.11859\teval-rmspe:0.1795\ttrain-rmspe:0.129469\n",
      "[385]\teval-rmse:0.134153\ttrain-rmse:0.118593\teval-rmspe:0.179464\ttrain-rmspe:0.129445\n",
      "[386]\teval-rmse:0.134152\ttrain-rmse:0.11859\teval-rmspe:0.179407\ttrain-rmspe:0.129458\n",
      "[387]\teval-rmse:0.134147\ttrain-rmse:0.118573\teval-rmspe:0.179386\ttrain-rmspe:0.129453\n",
      "[388]\teval-rmse:0.134152\ttrain-rmse:0.11857\teval-rmspe:0.179388\ttrain-rmspe:0.129281\n",
      "[389]\teval-rmse:0.134161\ttrain-rmse:0.118564\teval-rmspe:0.179441\ttrain-rmspe:0.129263\n",
      "[390]\teval-rmse:0.134153\ttrain-rmse:0.118546\teval-rmspe:0.179445\ttrain-rmspe:0.129234\n",
      "[391]\teval-rmse:0.134155\ttrain-rmse:0.11854\teval-rmspe:0.179394\ttrain-rmspe:0.129224\n",
      "[392]\teval-rmse:0.134154\ttrain-rmse:0.118529\teval-rmspe:0.179387\ttrain-rmspe:0.129205\n",
      "[393]\teval-rmse:0.134133\ttrain-rmse:0.118524\teval-rmspe:0.179231\ttrain-rmspe:0.129189\n",
      "[394]\teval-rmse:0.134117\ttrain-rmse:0.118493\teval-rmspe:0.1792\ttrain-rmspe:0.129165\n",
      "[395]\teval-rmse:0.134592\ttrain-rmse:0.118442\teval-rmspe:0.179188\ttrain-rmspe:0.129139\n",
      "[396]\teval-rmse:0.134597\ttrain-rmse:0.118429\teval-rmspe:0.179222\ttrain-rmspe:0.129134\n",
      "[397]\teval-rmse:0.134599\ttrain-rmse:0.118422\teval-rmspe:0.17911\ttrain-rmspe:0.129103\n",
      "[398]\teval-rmse:0.134603\ttrain-rmse:0.118325\teval-rmspe:0.179119\ttrain-rmspe:0.129083\n",
      "[399]\teval-rmse:0.134811\ttrain-rmse:0.118347\teval-rmspe:0.179116\ttrain-rmspe:0.129795\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, early_stopping_rounds=50, feval=rmspe_xg, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_response = gbm.predict(xgb.DMatrix(X_test))\n",
    "invalid_sales = validation_response < 0\n",
    "validation_response[invalid_sales] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1791158690512741"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(np.exp(validation_response) - 1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_response = gbm.predict(xgb.DMatrix(df_test))\n",
    "invalid_sales = final_response < 0\n",
    "final_response[invalid_sales] = 0\n",
    "\n",
    "store_closed = df_test['Open']==0\n",
    "final_response[store_closed] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_response = np.exp(final_response) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_response = pd.Series(final_response,index=id_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_response.to_csv('entry_9.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear/Ridge/Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = linear_model.LinearRegression()\n",
    "d_tree = lin_reg\n",
    "d_tree.fit(X_train_std, y_train)\n",
    "y_pred_lin = d_tree.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8369934011936219"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24079030091901818"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(y_pred_lin,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = linear_model.Ridge()\n",
    "lasso_reg = linear_model.Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg.fit(X_train_std, y_train)\n",
    "lasso_reg.fit(X_train_std, y_train)\n",
    "y_pred_ridge = ridge_reg.predict(X_test_std)\n",
    "y_pred_lasso = lasso_reg.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.836987033839252"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8369680296131354"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.240833458945162"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(y_pred_ridge,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24060942401659796"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(y_pred_lasso,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tree = DecisionTreeRegressor()\n",
    "d_tree.fit(X_train, y_train)\n",
    "y_pred_tree = d_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8425843357095362"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2286806725764097"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(y_pred_tree,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_st = neighbors.KNeighborsRegressor(n_neighbors=5)\n",
    "knn_st.fit(X_train_std, y_train)\n",
    "y_pred_knnst = knn_st.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,y_pred_knnst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmspe(y_pred_knnst,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestRegressor(random_state=123) \n",
    "clf_rf.fit(X_train_std, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8979439369248127"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20233909101300013"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(y_pred_rf,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(random_state=123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.fit(X_train_std, y_train)\n",
    "y_pred_gb = gb.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8859208211335522"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20921159073209736"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(y_pred_gb,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequental neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "input_dim = X_train_std.shape[1]\n",
    "\n",
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAE1CAYAAABqRtBXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmYXFWd//H3t5ZesncWIBskSGRJCEkIkBmQXQygwCBgUIfAMMZBR8VxZgB/agB1BmccZJgRFAFJlAEyuMD4sBiQiMwAkrAEwmICBNIEsu9Ldy3f3x/3VKfS6aXqJk13uJ/X89RTVeeee8+5t6r7W+fcc+8xd0dEREQ6luruCoiIiOwNFDBFREQqoIApIiJSAQVMERGRCihgioiIVEABU0REpAIKmCI9jJldbWY/7+56dMbMPm9mN3RzHb5jZqvN7L33udwfmdk398B2zjKzu/dEnaTrKWDKHmNmS82s2cwGt0p/3szczEZ1T81kTzOzGuAbwL92YRluZgd1sHwk8DXgMHffrwvrcbGZPVGe5u5/4+7f3t1tu/v9wDgzG7+725Kup4Ape9qbwIWlN2Z2OFDffdXpXmaW6Ullx6mPmaXbSD4beNXd34lTtz3kAGCNu6/sxjrsCXcBM7q7EtI5BUzZ034GXFT2fjowuzyDmdWa2ffN7G0zWxG6t+rDsgYz+42ZrTKzdeH1iLJ155nZt83sf81sk5n9tnWLtizv4LD+ejNba2Z/MLNUWDbRzJ4N27jHzO42s++EZbu0KMpbO2Z2ppk9Z2YbzWyZmV1dlm9UyHupmb0N/C6kTzGz/wt1ecHMTixbZ7SZ/T7UZS7Q5v6U5f94aLWvD9scX7ZsqZldYWYLgS1mlmkn7dBwLNeb2SIzO6tsG3eY2c1m9oCZbQFOaqMapwO/b1Wv48r2cZmZXRzS+5vZ7PCZvmVm3yj7HA4K+74hdK3eE9IfD5t9wcw2m9mnWpV1KjAXGBaW32FmJ5pZY6t8S0PeUlf3nFCXTWG/J5flHWlmvwz1XGNm/2lmhwI/Av4slLO+7Bh9p2zdz5nZkvA9u9/MhpUtczP7GzNbHL7TPzQzK6vmPODMNo6x9DTurocee+QBLAVOBV4DDgXSwDKiloADo0K+G4D7gYFAX+B/gH8OywYBnwR6hWX/Dfy6rIx5wOvAh4larvOA69qpzz8T/bPLhsdHAANqgLeAr4b084Ac8J2w3sXAE6225cBB4fWJwOFEPzjHAyuAc8KyUSHvbKB3qONwYA1wRljno+H9kLDOk8D1QC1wPLAJ+Hk7+zQJWAkcE47v9HDca8s+g+eBkUB9W2lhn5cAXw/H4uRQ5sEh/x3ABuDYUN+6NurxDHB+2fv9wzYuDNsfBEwIy2YD94XPcxTwJ+DSsOwu4P+VygGOa+uYt3MsTgQa23tf/p0Mr68GtofPIU30/XgqLEsDLwA/CJ9bS13a+T7cwY7vy8nA6vDZ1AL/ATzeaj9+AwwIx2kVMLVs+cCQp193/w3r0fFDLUzpCqVW5keBV4GWbrvwy/pzwFfdfa27bwL+CZgG4O5r3P0X7r41LPsucEKr7f/U3f/k7tuAOcCEduqRA4YCB7h7zt3/4NF/qClE/9RvCOn3EgWAirj7PHd/0d2L7r6Q6J9+6zpe7e5bQh0/Czzg7g+EdeYC84EzzGx/4Cjgm+7e5O6PE/2AaM/ngB+7+9PuXnD3WUBT2KeSG919WSi7rbQpQB+iHxrN7v47on/oF5blv8/d/zfUd3sb9RhAFCBLPgM84u53hWO6xt2ft6g791PAVe6+yd2XAv8G/GVYL0f0g2qYu293951a9l3gifA5FIi+p0eE9KOBYcA/hM+tmrp8Brjd3Z919ybgKqIW6aiyPNe5+3p3fxt4jJ2/s6XjOCDeLsn7RQFTusLPgE8T/TKf3WrZEKLW44LQdbceeCikY2a9zOzHoetuI/A4MMB2Po9WPiJyK9E//7b8K1FL6rdm9oaZXRnShwHvhOBZ8lalO2dmx5jZY6HrbgPwN+zajbqs7PUBwPml/Q37fBxRMB8GrHP3LRXW5QDga622NTJsp62y20obBixz92KrMod3so1y64hajCUjiVr+rQ1mR4u+rbL+kajV/8fQRfpXnZS7u1p/d+osOq87EnjL3fMxtjmMsv1z981EPQjlx7Oj72zpOK6PUba8jxQwZY9z97eIBv+cAfyy1eLVwDZgrLsPCI/+7l76B/I14GDgGHfvR9RFCdE/1Wrrscndv+buBwKfAP7OzE4B3gWGtzqPtH/Z6y1EQT0q2Kz1CMz/IupSHunu/Ym6fVvXrzwYLwN+Vra/A9y9t7tfF+rSYGa926lLa8uA77baVi93v6udsttKWw6MLJ1HLCvznXbyt2UhUbd4eb0+1Ea+1exoRe5Slru/5+6fc/dhwOeBm6yDkbGdaP25pQk/xCqwDNjf2h4U1dmxWE7Z/oXPchA7H8+OHAosdfeNFeaXbqKAKV3lUuDkVi0nQqvmJ8APzGwfADMbbmYfC1n6EgXU9WY2EJgZtwJhcMxBITBuBArh8SSQB74cBsCcS9QlV/ICMNbMJphZHdG5r3J9gbXuvt3MjiZqTXfk58AnzOxjZpY2s7owQGVE+HExH7jGzGrM7Dii4N6enwB/E1q5Zma9LRqE1LeDdVp7mii4/KOZZS0agPQJoJrrAR9g527oO4FTzeyCcEwHmdmE0PU5B/iumfU1swOAvyM6JpjZ+bZjUNc6ouBUCO9XAAdWUac/EbUYzzSzLNFlL7UVrvtHoh8v14VjWmdmx5bVY4RFl9K05b+AS8L3pZboFMPTofu5EicAD1aYV7qRAqZ0CXd/3d3nt7P4CqKu0qdCt+sjRK1KiAYE1RO1TJ4i6q6Na0zY9maiIHlTOP/YDJxL1GW8jugcW0tL2N3/BFwb1l0MtD6X9QXgWjPbBHyLKCC0y92XEV2G8XWiAR/LgH9gx9/fp4kG8awl+oHQuhu7fFvzic5j/meo+5KwHxUL+38W0UjX1cBNwEXu/moVm/kf4JDSaNBwbu4Moh6CtUSDjErnB79EFKDfIDqW/wXcHpYdBTxtZpuJWu1fcfc3w7KrgVmh6/mCCvZrA9FncytR624L0NjhSjvWLRD9aDgIeDusVxqZ+ztgEfCema1uY91HgW8CvyAKuh8inJOv0IXAj6vIL93Edj6NI5JMZnYH0QjLb3R3XfYWZjaD6KYBl3d3XfZWZvYJ4C/dvdMfBNL9FDBFUMAUkc6pS1ZERKQCamGKiIhUQC1MERGRCnTbjaHfb4MHD/ZRo0Z1dzVERKSbLFiwYLW7V3pt7i4SEzBHjRrF/PntXeUgIiIfdGZW8R292qIuWRERkQooYIqIiFRAAVNERKQCFQVMMxtgZvea2atm9oqZ/ZmZDTSzuWFS1Llm1hDympndGCZTXWhmk8q2Mz3kX2xm08vSjzSzF8M6N5Zuih2nDBERka5QaQvz34GH3P0QovtDvgJcCTzq7mOAR8N7iO5POSY8ZgA3QxT8iO6TeQzRja5nlgJgyDOjbL2pIb2qMkRERLpKpwHTzEpTLN0G0Y2b3X090c2kZ4Vss4BzwuuzgdkeeYpoLsOhwMeAuWHS4HXAXGBqWNbP3Z8M8xPObrWtasoQERHpEpW0MA8kmmHhp2b2nJndGuZ729fd3wUIz/uE/MPZefLZxpDWUXpjG+nEKENERKRLVBIwM8Ak4GZ3n0g0Zc6VHeRva6Jfj5HekYrWMbMZZjbfzOavWrWqk02KiIi0r5KA2Ug0i8PT4f29RAF0RakbNDyvLMs/smz9EUQzkneUPqKNdGKUsRN3v8XdJ7v75CFDYt/cQUREpPOA6e7vAcvMrDTB7ynAy0STvZZGuk4H7guv7wcuCiNZpwAbQnfqw8BpZtYQBvucBjwclm0ysylhdOxFrbZVTRntWrJyc2e7KiIi0q5Kb433JeBOM6shmjX9EqJgO8fMLiWaofz8kPcBopnXlwBbQ17cfa2ZfRt4JuS71t3XhteXAXcA9cCD4QFwXTVldKSoWVlERGQ3JGZ6r74jDvZNja91dzVERKSbmNkCd58cd/3E3OknGT8LRESkqyQnYCakJS0iIl0jMQFTRERkdyQmYKqBKSIiuyM5AbO7KyAiInu15ARMNTFFRGQ3JCdgdncFRERkr5aYgAlQLCpsiohIPIkKmLlisburICIie6lEBcx8QS1MERGJRwFTRESkAokKmOqSFRGRuBIVMNXCFBGRuJIVMNXCFBGRmJIVMNXCFBGRmJIVMNXCFBGRmBIVMHNqYYqISEyJCpjqkhURkbgSFTB1WYmIiMSVqIBZ0L1kRUQkpkQFzFxBLUwREYknUQFT5zBFRCSuZAVMncMUEZGYEhUwdVmJiIjElaiAqUE/IiISV6ICpgb9iIhIXIkKmBr0IyIicSUrYGrQj4iIxJSogKlBPyIiEleiAmZe5zBFRCSmZAVMjZIVEZGYFDBFREQqkKyAqS5ZERGJKVEBU4N+REQkrkQFTF1WIiIicSUmYBq6cYGIiMSXnIBppkE/IiISW3ICJhr0IyIi8VUUMM1sqZm9aGbPm9n8kDbQzOaa2eLw3BDSzcxuNLMlZrbQzCaVbWd6yL/YzKaXpR8Ztr8krGtxy2h/HyCnFqaIiMRUTQvzJHef4O6Tw/srgUfdfQzwaHgPcDowJjxmADdDFPyAmcAxwNHAzFIADHlmlK03NU4ZHTFMLUwREYltd7pkzwZmhdezgHPK0md75ClggJkNBT4GzHX3te6+DpgLTA3L+rn7k+7uwOxW26qmjPaZBv2IiEh8lQZMB35rZgvMbEZI29fd3wUIz/uE9OHAsrJ1G0NaR+mNbaTHKWMnZjbDzOab2fxioaBBPyIiElumwnzHuvtyM9sHmGtmr3aQ19pI8xjpHaloHXe/BbgFoN/Ig13XYYqISFwVtTDdfXl4Xgn8iugc5IpSN2h4XhmyNwIjy1YfASzvJH1EG+nEKKNdhulOPyIiElunAdPMeptZ39Jr4DTgJeB+oDTSdTpwX3h9P3BRGMk6BdgQulMfBk4zs4Yw2Oc04OGwbJOZTQmjYy9qta1qyuhgP3RZiYiIxFdJl+y+wK/ClR4Z4L/c/SEzewaYY2aXAm8D54f8DwBnAEuArcAlAO6+1sy+DTwT8l3r7mvD68uAO4B64MHwALiumjI6YqbZSkREJD6LBqZ+8A084BA/7f/9lLtn/Fl3V0VERLqBmS0ouzSyaom50w8YBbUwRUQkpsQETDNN7yUiIvElKmDqshIREYkrOQET051+REQktuQETIOcLisREZGYkhMw0WUlIiISX2ICpm6+LiIiuyMxAdMwDfoREZHYkhMw1cIUEZHdkJyAiQb9iIhIfMkJmGYa9CMiIrElJ2CiUbIiIhJfcgKmpvcSEZHdkJiACVB0KKqVKSIiMSQmYIb5PMnp0hIREYkhOQEzPOvSEhERiSM5ATNETAVMERGJIzkBM7QxdbcfERGJIzkBs9TC1KAfERGJITkBMzzrbj8iIhJHcgKmzmGKiMhuSEzALEVMncMUEZE4EhMwd3TJqoUpIiLVS1zALGjQj4iIxJCcgFm6048G/YiISAwJCpjRsy4rERGROJITMMOzWpgiIhJHYgImuqxERER2Q2ICpm6NJyIiuyM5AVMtTBER2Q3JCZjhWYN+REQkjuQETF1WIiIiuyE5ATM8q0tWRETiSEzAbBklq0E/IiISQ2IC5o5RsmphiohI9ZITMDVKVkREdkNyAmZ41qAfERGJo+KAaWZpM3vOzH4T3o82s6fNbLGZ3WNmNSG9NrxfEpaPKtvGVSH9NTP7WFn61JC2xMyuLEuvuoz26x89q0tWRETiqKaF+RXglbL33wN+4O5jgHXApSH9UmCdux8E/CDkw8wOA6YBY4GpwE0hCKeBHwKnA4cBF4a8VZfRkZZzmGphiohIDBUFTDMbAZwJ3BreG3AycG/IMgs4J7w+O7wnLD8l5D8buNvdm9z9TWAJcHR4LHH3N9y9GbgbODtmGR3sQ/SsCaRFRCSOSluYNwD/CJSaZ4OA9e6eD+8bgeHh9XBgGUBYviHkb0lvtU576XHK2ImZzTCz+WY2f9WqVaRME0iLiEg8nQZMM/s4sNLdF5Qnt5HVO1m2p9I7K39Hgvst7j7Z3ScPGTKETDpFTtdhiohIDJkK8hwLnGVmZwB1QD+iFucAM8uEFt4IYHnI3wiMBBrNLAP0B9aWpZeUr9NW+uoYZXQomzJdViIiIrF02sJ096vcfYS7jyIatPM7d/8M8BhwXsg2HbgvvL4/vCcs/527e0ifFka4jgbGAH8EngHGhBGxNaGM+8M61ZbRoUw6pUE/IiISSyUtzPZcAdxtZt8BngNuC+m3AT8zsyVErb5pAO6+yMzmAC8DeeCL7l4AMLO/BR4G0sDt7r4oThmdyaaNnM5hiohIDFZBw+wDYfLkyZ4+9zpO+PAQ/uW8I7q7OiIi8j4zswXuPjnu+om50w9AJpXSjQtERCSW3emS3etk0xr0IyI9Sy6Xo7Gxke3bt3d3VT4w6urqGDFiBNlsdo9uN1EBM5NOaXovEelRGhsb6du3L6NGjaKT+69IBdydNWvW0NjYyOjRo/fothPWJWu604+I9Cjbt29n0KBBCpZ7iJkxaNCgLmmxJytgpk2XlYhIj6NguWd11fFMVsDUoB8REYkpUQFTg35ERHa1fv16brrppqrXO+OMM1i/fn2Heb71rW/xyCOPxK1aj5KogBm1MNUlKyJSrr2AWSgUOlzvgQceYMCAAR3mufbaazn11FN3q349RbICZlqDfkREWrvyyit5/fXXmTBhAkcddRQnnXQSn/70pzn88MMBOOecczjyyCMZO3Yst9xyS8t6o0aNYvXq1SxdupRDDz2Uz33uc4wdO5bTTjuNbdu2AXDxxRdz7733tuSfOXMmkyZN4vDDD+fVV18FYNWqVXz0ox9l0qRJfP7zn+eAAw5g9erV7/NR6FyiLivJ6rISEenBrvmfRby8fOMe3eZhw/ox8xNjO8xz3XXX8dJLL/H8888zb948zjzzTF566aWWyzJuv/12Bg4cyLZt2zjqqKP45Cc/yaBBO8+ouHjxYu666y5+8pOfcMEFF/CLX/yCz372s7uUNXjwYJ599lluuukmvv/973PrrbdyzTXXcPLJJ3PVVVfx0EMP7RSUe5JEtTDTmq1ERKRTRx999E7XMN54440cccQRTJkyhWXLlrF48eJd1hk9ejQTJkwA4Mgjj2Tp0qVtbvvcc8/dJc8TTzzBtGnRLcGnTp1KQ0PDHtybPSdhLUzTKFkR6bE6awm+X3r37t3yet68eTzyyCM8+eST9OrVixNPPLHNaxxra2tbXqfT6ZYu2fbypdNp8vk8EN1sYG+QqBZmJqXpvUREWuvbty+bNm1qc9mGDRtoaGigV69evPrqqzz11FN7vPzjjjuOOXPmAPDb3/6WdevW7fEy9oREtTA16EdEZFeDBg3i2GOPZdy4cdTX17Pvvvu2LJs6dSo/+tGPGD9+PAcffDBTpkzZ4+XPnDmTCy+8kHvuuYcTTjiBoUOH0rdv3z1ezu5K1PRep1x5O/P+tJKnv/7BGOIsInu/V155hUMPPbS7q9GtmpqaSKfTZDIZnnzySS677DKef/753dpmW8d1d6f3SlwLU4N+RER6lrfffpsLLriAYrFITU0NP/nJT7q7Sm1KVsBMGTmdwxQR6VHGjBnDc889193V6FSyBv2kUxQ0SlZERGJIWMA0cgqYIiISQ6ICZlaXlYiISEyJCpiZtFF0KKqVKSIiVUpWwExFk4rmdD9ZEZHY+vTpA8Dy5cs577zz2sxz4oknMn/+/A63c8MNN7B169aW95VMF9adkhUw09HuauCPiMjuGzZsWMtMJHG0DpiVTBfWnZIVMEstTF2LKSLS4oorrthpPsyrr76aa665hlNOOaVlKq777rtvl/WWLl3KuHHjANi2bRvTpk1j/PjxfOpTn9rpXrKXXXYZkydPZuzYscycOROIbui+fPlyTjrpJE466SRgx3RhANdffz3jxo1j3Lhx3HDDDS3ltTeN2PshUddhZkMLUwN/RKRHevBKeO/FPbvN/Q6H06/rMMu0adO4/PLL+cIXvgDAnDlzeOihh/jqV79Kv379WL16NVOmTOGss87CzNrcxs0330yvXr1YuHAhCxcuZNKkSS3Lvvvd7zJw4EAKhQKnnHIKCxcu5Mtf/jLXX389jz32GIMHD95pWwsWLOCnP/0pTz/9NO7OMcccwwknnEBDQ0PF04h1hWS1MNPRB60ZS0REdpg4cSIrV65k+fLlvPDCCzQ0NDB06FC+/vWvM378eE499VTeeecdVqxY0e42Hn/88ZbANX78eMaPH9+ybM6cOUyaNImJEyeyaNEiXn755Q7r88QTT/AXf/EX9O7dmz59+nDuuefyhz/8Aah8GrGukKwWZir6faC7/YhIj9RJS7ArnXfeedx777289957TJs2jTvvvJNVq1axYMECstkso0aNanNar3JttT7ffPNNvv/97/PMM8/Q0NDAxRdf3Ol2OrrHeaXTiHWFRLUw0+Ecpu4nKyKys2nTpnH33Xdz7733ct5557Fhwwb22Wcfstksjz32GG+99VaH6x9//PHceeedALz00kssXLgQgI0bN9K7d2/69+/PihUrePDBB1vWaW9aseOPP55f//rXbN26lS1btvCrX/2Kj3zkI3twb+NJVAtTXbIiIm0bO3YsmzZtYvjw4QwdOpTPfOYzfOITn2Dy5MlMmDCBQw45pMP1L7vsMi655BLGjx/PhAkTOProowE44ogjmDhxImPHjuXAAw/k2GOPbVlnxowZnH766QwdOpTHHnusJX3SpElcfPHFLdv467/+ayZOnPi+dr+2JVHTe1370//hC3c+y0OXf4RD9uvX3VUSEdH0Xl2kK6b3SlSXbEZdsiIiElOiAmbpshIN+hERkWolKmDqHKaI9ERJOTX2fumq45mogJluudOPWpgi0jPU1dWxZs0aBc09xN1Zs2YNdXV1e3zbiRolm9W9ZEWkhxkxYgSNjY2sWrWqu6vygVFXV8eIESP2+HYTFTA16EdEeppsNsvo0aO7uxpSgUR1yWrQj4iIxNVpwDSzOjP7o5m9YGaLzOyakD7azJ42s8Vmdo+Z1YT02vB+SVg+qmxbV4X018zsY2XpU0PaEjO7siy96jI6okE/IiISVyUtzCbgZHc/ApgATDWzKcD3gB+4+xhgHXBpyH8psM7dDwJ+EPJhZocB04CxwFTgJjNLm1ka+CFwOnAYcGHIS7VldCaje8mKiEhMnQZMj2wOb7Ph4cDJQGnm0FnAOeH12eE9YfkpFt2R92zgbndvcvc3gSXA0eGxxN3fcPdm4G7g7LBOtWV0qHQOU4N+RESkWhWdwwwtweeBlcBc4HVgvbvnQ5ZGYHh4PRxYBhCWbwAGlae3Wqe99EExyuhQS5esBv2IiEiVKgqY7l5w9wnACKIWYVs3PixFobZaer4H0zsqYydmNsPM5pvZ/FWrVu0Y9FNUl6yIiFSnqlGy7r4emAdMAQaYWemylBHA8vC6ERgJEJb3B9aWp7dap7301THKaF3fW9x9srtPHjJkiC4rERGR2CoZJTvEzAaE1/XAqcArwGPAeSHbdOC+8Pr+8J6w/Hce3cLifmBaGOE6GhgD/BF4BhgTRsTWEA0Muj+sU20ZHcroshIREYmpkhsXDAVmhdGsKWCOu//GzF4G7jaz7wDPAbeF/LcBPzOzJUStvmkA7r7IzOYALwN54IvuXgAws78FHgbSwO3uvihs64pqyuh0Z1O6rEREROLpNGC6+0JgYhvpbxCdz2ydvh04v51tfRf4bhvpDwAP7IkyOlIa9KNRsiIiUq1k3elH12GKiEhMiQqYqZSRMg36ERGR6iUqYEI08EeXlYiISLUSFzCzKVMLU0REqpa4gJlOGXmdwxQRkSolLmBm0yldViIiIlVLXMDMpNUlKyIi1UtewExp0I+IiFQvcQEzqxamiIjEkLiAmUmnyKuFKSIiVUpewNRlJSIiEkPyAmbaNEpWRESqlryAmUrpXrIiIlK1xAVMDfoREZE4EhcwMykN+hERkeolL2CmjZxamCIiUqXkBcyUaQJpERGpWvICZlqDfkREpHqJC5hZXVYiIiIxJC5gZlIpTe8lIiJVS17A1KAfERGJIXkBM2W6rERERKqWvICZTmmUrIiIVC1xATObUpesiIhUL3EBM5PWoB8REaleAgOmkVOXrIiIVClxATOry0pERCSGxAXMdMooOhTVyhQRkSokLmBm0wagu/2IiEhVEhcwM+lol3UtpoiIVCN5ATMVtTB1aYmIiFQjcQEzW2phauCPiIhUIXEBM6NzmCIiEkPyAmZKAVNERKqXwICpLlkREale8gJmWoN+RESkeokLmFldViIiIjF0GjDNbKSZPWZmr5jZIjP7SkgfaGZzzWxxeG4I6WZmN5rZEjNbaGaTyrY1PeRfbGbTy9KPNLMXwzo3mpnFLaMzLecw1cIUEZEqVNLCzANfc/dDgSnAF83sMOBK4FF3HwM8Gt4DnA6MCY8ZwM0QBT9gJnAMcDQwsxQAQ54ZZetNDelVlVGJHV2yamGKiEjlOg2Y7v6uuz8bXm8CXgGGA2cDs0K2WcA54fXZwGyPPAUMMLOhwMeAue6+1t3XAXOBqWFZP3d/0t0dmN1qW9WU0anSoB9NIi0iItWo6hymmY0CJgJPA/u6+7sQBVVgn5BtOLCsbLXGkNZRemMb6cQoo1Ma9CMiInFUHDDNrA/wC+Byd9/YUdY20jxGeofVqWQdM5thZvPNbP6qVasADfoREZF4KgqYZpYlCpZ3uvsvQ/KKUjdoeF4Z0huBkWWrjwCWd5I+oo30OGXsxN1vcffJ7j55yJAhgAb9iIhIPJWMkjXgNuAVd7++bNH9QGmk63TgvrL0i8JI1inAhtCd+jBwmpk1hME+pwEPh2WbzGxKKOuiVtuqpoxOlVqYGvQjIiLVyFSQ51jgL4EXzez5kPZ14DpgjpldCrwNnB+WPQCcASwBtgKXALj7WjP7NvBMyHetu68Nry8D7gDqgQdvoHsNAAAR10lEQVTDg2rLqERat8YTEZEYOg2Y7v4EbZ8zBDiljfwOfLGdbd0O3N5G+nxgXBvpa6otozOaQFpEROJI3J1+dC9ZERGJI3kBM61BPyIiUr3EBcyWQT+6rERERKqQuICpy0pERCSOBAbM0o0LFDBFRKRyyQuYLecw1SUrIiKVS27AVAtTRESqkLiAmU3pTj8iIlK9xAXMVMpImQb9iIhIdRIXMCEa+KPLSkREpBrJDJhpo6AWpoiIVCGZATNlGvQjIiJVSWTAzKZTGvQjIiJVSWTAzKRNg35ERKQqyQmYG99pealBPyIiUq3kBMzNK+HtpwG1MEVEpHrJCZjpGvjN5VDIkUkZBQ36ERGRKiQnYPYfCStfhv/7Dw36ERGRqiUnYNb1g0PPgt9/j+Gs0GUlIiJSleQETIDTvwepLJdv/xHPv72OlZu2d3eNRERkL5GsgNlvGJzyLQ7fPp8Tc4/z9/+9kKJamiIiUoFkBUyAoy6FYZP4p/qf89KfXuf2/32zu2skIiJ7geQFzFQazv4htYUt/HjQ3XzvoVd56Z0N3V0rERHp4ZIXMAH2PQw74QqO2jKP8+oX8OW7n2Nrc767ayUiIj1YMgMmwLGXw9AJXJu+nfWr3+Ubv3oJd53PFBGRtiU3YKYzcM5NZHObuGv4L/nlc+9w2xM6nykiIm1LbsAE2HcsnHAFB6/+Ld86YBH/9MArzHttZXfXSkREeqBkB0yA4y6HEUdzyYp/4pv9H+JLdz3L66s2d3etRESkh1HATGfhovuwcZ/kku2zuZ4f8KU7/sDaLc3dXTMREelBMt1dgR6hphd88lYYNoFT536LkZv+gauv+ySDD5zInx91FMcfMpSajH5biIgkmSVlZOjkyZN9/vz5nWd8/Xfk//uvyGxfB0CTZ1hqw9laM5h8TX8KdQOw+gZStX1I1dSTru1NuqYX2WyWTDZLJpMlnSk915DJZklna0jX1JOpqSeVrSNbU4tZCswAi64NTWWi1m4qEz3MuvaAiIgkjJktcPfJcddXC7O1D51M5muvwurXyL+3iPdee5ZC4yL6Nq2hbuu79N68iX6+mbR1/Q+NAimKpHAMxyhieEgrWJoiKYqWBmjJCbA91Ztt6T5sT/elKdOXQl0DXt9AutcgMv2GUNMwnD6DR9J/3/3p1ac/puAsItIpBcy2ZOtg6BFkhh7BARM/vcviXL7A5q1b2LZ1E9u3bKZp22aacznyuRy5XI5cvpliPkc+n6OYz1HMNUGhGSs0YfltkM/hFCkWHXfHiwWsmMOKBcxzUCyCF8ELmEev3YuYE9KidPM85gUcKLhRdMPdqStuoVdhM71zGxlQXE6/DZvoR9tBfovXstH6sjnVj63pfjRlo1a01w8k3Wsg2Ybh9Nrvwww64FAGNQwilVJwFZFkUsCMIZtJ079fP/r369fdVamIu7OtOcfaNavZvOZdtq19h+Z17+Abl5PaspJ003pqcuupz21g0PYl9N66iX6+aZcAu9IHsCK9H+tr9mNL/TByfUbAkIPpvf8RDN9vP/Yf2Iv6mnQ37aWISNdSwEwAM6NXbQ29hg2DYcOAIztdp1gosH79Wta++wabl79GYdVi0utep37rOxzc9AoDt/+BzLoCLAOehbeK+zDPD2BF7ShyAz9M/bDD2Gf04Ryw70BGDqynV42+aiKyd9N/MWlTKp1mwKAhDBg0BMYds2uGYgHf+A5blr3IpqXPkXnvRaasfZn+2xaQWlmElVB8zlhDP97wBtamB7G9ZjCWrSOVyZLJ1pDO1GBhsJOls6TSKVJeIEOBNAUsqgiWyuCpDKTSeCqLWwZPZUmZky7mSXuOlOcgXUexvj/UDsDrB0DdAFL1/bH6AdTU9Wb/Qb1Jq0tZRGJSwJR4UmlswP70GbA/fQ4/c0d6bjusfZ3md19m7VuLaFq7jL6b3mXg1hX0an6DdHOOlEcBMeN5MlZ8X6rb5FmW2DDW9RlDdtjhDD1oAgP71FJLM1bIQaEZ0jWQqYvOYadrgHaCa/noZktFj2Iectsgvz16FAthmUXP6VrI1kePTG10nJo2wvYN0Lw5KremD9T0hmwvyG+D5q3QvCWqW20fqO0Hdf2i5cUCeCF6hp1HWZeXa6nofHixsPOzFwGPntM1UZ0yoW5ejMosNEMhD8VctH+FHLhH5WRqo/XSNWUjukvPHuWDlnPxFMPDbEd5pXVbj9RvXXcv7jiv39ZnUBpZnsrsKM+L0XZL20mlo/yl9coHupXKN6tsdHohH74v2Xgj2svLS5JCDpo2Rd/zTE131yYWBUzZs7J1sO9YavYdy34Tzu88vzvFfI5cvolcLk/BMhRJRyOEHYrFIoVCDs/nKBZyUMjhhRxeyOMGRashbxnyZCC/Dd+6Dt++Adu2HmvagDVtJNW0Htu6Bl/5Ggdufo59/vQI/KnrD4XsnYqkcUtRtBSQwi0aqZ7yPOliMymKZXlTFFI1FFI10Vh2d6AYDdYrYxAN1qNIyqMfOUXLUExlKFjUa4KBk8LNdpRrKcp/uFnYtlu6Zf2iZTAvhvrlMM9T+lHgYR9KdTIvYhQpWga3dHikMM+T8gJWLJDyPFbMk/IcVsyDpSik6yik6ymk6yima8rWTUdj94u56OG5aFR/2bYzuc3UNK8jk9txB7V8pje5mgHka/qCpcM+R3tYXk+8SKrQRKqYw4rRzWSK6XqKmXoKmXqK6dqo1ymVxUs/csOPLKP1Z7D7P1A6DZhmdjvwcWClu48LaQOBe4BRwFLgAndfZ9H1Cf8OnAFsBS5292fDOtOBb4TNfsfdZ4X0I4E7gHrgAeAr7u5xypC9kBmpbA212Rpq67u+OHfn7cZlvP7qC6zdVmBdc4o122FDE6QKzWS8mbQ3ky7mdsxe4+B4dNFOSIv+8ZUu+HGKQBO1NFmW7V5DgVTUwAn/qLLkqfEmammi1ptpoobN9Gaz9WILdWQ9R31xK3Vsp86baLIatlPHdqslR5Zevo1evpXevoVab6JgKfKeCpcaQdqji5DSHv7hhTpGdTMKnmq5TKlUt2LIkfU8NTRTSzM1NFMgTZ40OTLkQgd5ngz5sH6WPFly1JAjSz7sp7c8R23XMGqb6PKoUtkANZ4jS46s54iObJSv6EbKPFw8FV0qVcQoYBRb9tVCbkiFi6wyRN34KQoUPUUeo+AWPidIUyRl3hLorPQZmuMhX2m7KSuSJnpE9fCWS7bypGkiS7NHxyVNkVprppYcteTCpV876tl6THrp2BeIBsZlyJOlQJY8GQphrfDdKpVdVu8dx9RIW2m/o20USIXPK03eM+H4FFuOZ2ndQrhMLU2RtBXIhH3Nk4o+Y4/2Nhc+8xxpUjh1NFNPE/XWRE34JkTr5imSopk6cvQhH/YtTWnbBTbTwDo/jHXel03U05vtNOQ3M6BpE/3Y2nI5XOmoFcjgLd8Zo5kMzZ4lF8JVnTVRH+pTxxYylidLnlry4Thb2WdQ/mNj9y8F7PTGBWZ2PLAZmF0WMP8FWOvu15nZlUCDu19hZmcAXyIKZscA/+7ux4TgNx+YDDiwADgyBMA/Al8BniIKmDe6+4PVltHZjlZ84wIR2eu5hwButHudcbHoIVA7haJ32kNa+ldZdKfYxr9N92h77rT8yCr6jvS2tudRRpzQjjRC6I4Six6VR7TJlnJK+2Ts6NX20j6VfuCFdVvqFLZSOi5gLfscLfewf+y0jVL+lFlZWTuWlb8uuLfUKVV2QEvHrOg7QlhpH7xs/0r1KO1PZ/fVKR3bYmmFsHFj57qWjvFxY4Z07Y0L3P1xMxvVKvls4MTwehYwD7gipM/26Ag8ZWYDzGxoyDvX3dcCmNlcYKqZzQP6ufuTIX02cA7wYLVluPu71e26iHxQmVmnAbB0TXEaI6uroaQCcW+Qum8pQIXnfUL6cKILDUoaQ1pH6Y1tpMcpYxdmNsPM5pvZ/FWrVlW1gyIiIuX29B3F2/pN5zHS45Sxa6L7Le4+2d0nDxkypJPNioiItC9uwFwRuloJz6VZlxuBkWX5RgDLO0kf0UZ6nDJERES6TNyAeT8wPbyeDtxXln6RRaYAG0J36sPAaWbWYGYNwGnAw2HZJjObEka/XtRqW9WUISIi0mUquazkLqLBN4PNrBGYCVwHzDGzS4G3gdIFdw8QjV5dQnTJxyUA7r7WzL4NPBPyXVsaAARcxo7LSh4MD6otQ0REpCtpPkwREUmE3Z0Pc08P+hEREflAUsAUERGpgAKmiIhIBRJzDtPMVgFvdXc99gKDgdXdXYm9kI5bPDpu8ei4xXOwu/eNu3JiZitxd925oAJmNn93ToonlY5bPDpu8ei4xWNmuzXyU12yIiIiFVDAFBERqYACprR2S3dXYC+l4xaPjls8Om7x7NZxS8ygHxERkd2hFqaIiEgFFDATzMxGmtljZvaKmS0ys6+E9IFmNtfMFofnhu6ua09jZmkze87MfhPejzazp8Mxu8fMarq7jj1NmOz9XjN7NXzn/kzftc6Z2VfD3+dLZnaXmdXp+7YrM7vdzFaa2UtlaW1+v8LkHTea2RIzW2hmkyopQwEz2fLA19z9UGAK8EUzOwy4EnjU3ccAj4b3srOvAK+Uvf8e8INwzNYBl3ZLrXq2fwcecvdDgCOIjp++ax0ws+HAl4HJ7j4OSAPT0PetLXcAU1ultff9Oh0YEx4zgJsrKUABM8Hc/V13fza83kT0D2w4cDYwK2SbBZzTPTXsmcxsBHAmcGt4b8DJwL0hi45ZK2bWDzgeuA3A3ZvdfT36rlUiA9SbWQboBbyLvm+7cPfHgbWtktv7fp0NzPbIU8CA0vzLHVHAFADMbBQwEXga2Lc0x2h43qf7atYj3QD8I1AM7wcB6909H943Ev3wkB0OBFYBPw1d2beaWW/0XeuQu78DfJ9oisN3gQ3AAvR9q1R736/hwLKyfBUdQwVMwcz6AL8ALnf3jd1dn57MzD4OrHT3BeXJbWTV8POdZYBJwM3uPhHYgrpfOxXOuZ0NjAaGAb2JuhNb0/etOrH+ZhUwE87MskTB8k53/2VIXlHqngjPK7urfj3QscBZZrYUuJuoa+wGoi6d0q0mRwDLu6d6PVYj0OjuT4f39xIFUH3XOnYq8Ka7r3L3HPBL4M/R961S7X2/GoGRZfkqOoYKmAkWzr3dBrzi7teXLbofmB5eTwfue7/r1lO5+1XuPsLdRxENvvidu38GeAw4L2TTMWvF3d8DlpnZwSHpFOBl9F3rzNvAFDPrFf5eS8dN37fKtPf9uh+4KIyWnQJsKHXddkQ3LkgwMzsO+APwIjvOx32d6DzmHGB/oj/Y89299cn0xDOzE4G/d/ePm9mBRC3OgcBzwGfdvak769fTmNkEooFSNcAbwCVEP9r1XeuAmV0DfIpoVPtzwF8TnW/T962Mmd0FnEg0k8sKYCbwa9r4foUfH/9JNKp2K3CJu3d6Y3YFTBERkQqoS1ZERKQCCpgiIiIVUMAUERGpgAKmiIhIBRQwRUREKqCAKSJAdJlMafYVEdmVAqaIiEgFFDBF9jJm9lkz+6OZPW9mPw5zc242s38zs2fN7FEzGxLyTjCzp8Kcf78qmw/wIDN7xMxeCOt8KGy+T9mclXeGC7xFBAVMkb2KmR1KdNeXY919AlAAPkN0U+5n3X0S8Huiu5wAzAaucPfxRHd0KqXfCfzQ3Y8gujdp6bZgE4HLgcOIZhg5tst3SmQvkek8i4j0IKcARwLPhMZfPdENpYvAPSHPz4Ffmll/YIC7/z6kzwL+28z6AsPd/VcA7r4dIGzvj+7eGN4/D4wCnuj63RLp+RQwRfYuBsxy96t2SjT7Zqt8Hd3zsqNu1vL7kRbQ/wiRFuqSFdm7PAqcZ2b7AJjZQDM7gOhvuTR7xaeBJ9x9A7DOzD4S0v8S+H2Y87TRzM4J26g1s17v616I7IX061FkL+LuL5vZN4DfmlkKyAFfJJqQeayZLQA2EJ3nhGhKox+FgFiaIQSi4PljM7s2bOP893E3RPZKmq1E5APAzDa7e5/urofIB5m6ZEVERCqgFqaIiEgF1MIUERGpgAKmiIhIBRQwRUREKqCAKSIiUgEFTBERkQooYIqIiFTg/wMSf2f4CR0cFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1bd93860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5cc3ee48>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_std, y_train, batch_size = 20, epochs = 100,validation_split=0.2, callbacks=[PlotLossesKeras()], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8916858252953622"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5598.5107],\n",
       "       [ 4389.9336],\n",
       "       [12234.975 ],\n",
       "       [ 6292.384 ],\n",
       "       [15207.395 ],\n",
       "       [ 4200.547 ],\n",
       "       [ 4593.0728],\n",
       "       [ 5186.2017],\n",
       "       [14055.232 ]], dtype=float32)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20671134598551266"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(y_pred.flatten(),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "dtc = DecisionTreeRegressor()\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "stregr = StackingRegressor(regressors=[dtc, lr], meta_regressor=rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = stregr.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stack = stack.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8417806154308942"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23062896703138935"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(y_pred_stack,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR(kernel='linear')\n",
    "svr.fit(X_train_std, y_train)\n",
    "y_pred_svr = svr.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,y_pred_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmspe(y_pred_svr,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para_bag = {'base_estimator':[DecisionTreeRegressor(), KNeighborsRegressor()],\"max_samples\": [0.5, 1.0],}\n",
    "bag = BaggingRegressor()\n",
    "# grid_bag = GridSearchCV(bag, para_bag, cv = 5, scoring = two_scorer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag.base_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bag = bag.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test,y_pred_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmspe(y_pred_bag,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
